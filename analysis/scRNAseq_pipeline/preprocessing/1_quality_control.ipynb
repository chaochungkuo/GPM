{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"QC of scRNA-seq\"\n",
    "author: \"Mohamed Mabrouk\"\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    html-math-method: katex\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "    page-layout: full\n",
    "execute:\n",
    "    echo: true\n",
    "    warning: false\n",
    "jupyter:\n",
    "  kernelspec:\n",
    "    name: \"pixi-kernel-python3\"\n",
    "    language: \"python\"\n",
    "    display_name: \"pixi-kernel-python3\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.2.min.js\", \"https://cdn.holoviz.org/panel/1.4.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1002'>\n",
       "  <div id=\"c1bd7d30-826e-4da6-a4c0-da3e560b931b\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"be9c9b33-886c-4039-9af7-52b68b5918cd\":{\"version\":\"3.4.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1002\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1003\",\"attributes\":{\"plot_id\":\"p1002\",\"comm_id\":\"d839dc1669614409ba50426c469a3312\",\"client_comm_id\":\"eabbbdf95f304ae38eb67d96e22e8fb5\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"be9c9b33-886c-4039-9af7-52b68b5918cd\",\"roots\":{\"p1002\":\"c1bd7d30-826e-4da6-a4c0-da3e560b931b\"},\"root_ids\":[\"p1002\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "import logging\n",
    "from os import cpu_count, listdir, mkdir, path, walk\n",
    "from typing import Dict, List\n",
    "\n",
    "import anndata as ad\n",
    "import hvplot\n",
    "import hvplot.pandas\n",
    "import itables\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import panel as pn\n",
    "import patchworklib as pw\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import session_info\n",
    "import tomlkit\n",
    "from IPython.display import Markdown, display\n",
    "from matplotlib import rc_context\n",
    "from utils.preprocessing_funcs import *\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "sc.set_figure_params(dpi=100, dpi_save=300, format=\"png\")\n",
    "sc.settings.n_jobs = int(cpu_count() * 0.8)\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: true\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "\"in the following cell, override the default pipeline parameters if needed\"\n",
    "\n",
    "# QC Params\n",
    "\n",
    "# check QC and filter cells for each sample separately, default: True.\n",
    "QC_PER_SAMPLE: bool = True\n",
    "\n",
    "# Correct ambient RNA, uses DecontX.\n",
    "CORRECT_AMBIENT_RNA: bool = False\n",
    "\n",
    "# Filter doublets using Scrublet\n",
    "FILTER_DOUBLETS: bool = False\n",
    "\n",
    "# Calculate cell cycle scores, based on scanpy implementation.\n",
    "CELL_CYCLE_SCORE: bool = True\n",
    "\n",
    "\n",
    "############################################################\n",
    "####################     QC Dict      ######################\n",
    "############################################################\n",
    "\n",
    "\"\"\"\n",
    "Can either be a flat-dict for global threshold or a dict of dicts for each sample \n",
    "Entries in the form of col_name: [low, high] Ex: 'pct_counts_mt':[0, 20] which will be used as (low, high) pair.\n",
    "Also entries can be a single number Ex: 'pct_counts_mt': 3 which be used as number of MADS as follows media -+ nmad * MAD. \n",
    "You can mix and match as needed in global config or per sample.\n",
    "\"\"\"\n",
    "\n",
    "# by default, filtering on read counts, number of features, and mitochondrial content\n",
    "qc_dict: Dict[str, List] | Dict[str, Number] = {\n",
    "    \"n_genes_by_counts\": 5,\n",
    "    \"total_counts\": 5,\n",
    "    \"pct_counts_mt\": 3,\n",
    "}\n",
    "\n",
    "# MODIFY_ME, Specifiy only after running diagnotics on the samples\n",
    "# global config\n",
    "# qc_dict: Dict[str, List] | Dict[str, List] = {\n",
    "#     \"pct_counts_mt\": [0, 10],\n",
    "#     \"pct_counts_rb\": [0, 10],\n",
    "#     \"n_genes_by_counts\": [1500, 9000],\n",
    "#     \"total_counts\": [3_000, 40_000]\n",
    "# }\n",
    "\n",
    "\n",
    "# # per-sample config\n",
    "# qc_dict: Dict[str, List] | Dict[str, List] = {\n",
    "#     \"sample1\": {\n",
    "#         \"pct_counts_mt\": [0, 10],\n",
    "#         \"pct_counts_rb\": 5,\n",
    "#         \"total_counts\": [3_000, 40_000]\n",
    "#     },\n",
    "#     \"sample2\": {\n",
    "#         \"pct_counts_rb\": 3,\n",
    "#         \"n_genes_by_counts\": [1500, 9000],\n",
    "#         \"total_counts\": [3_000, 40_000]\n",
    "#     },\n",
    "#     \"sample3\": {\n",
    "#         \"pct_counts_mt\": [0, 10],\n",
    "#         \"n_genes_by_counts\": [1500, 9000],\n",
    "#         \"total_counts\": [3_000, 40_000]\n",
    "#     },\n",
    "#     \"sample4\": {\n",
    "#         \"pct_counts_mt\": 4\n",
    "#         \"pct_counts_rb\": 5,\n",
    "#         \"n_genes_by_counts\": 6,\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "## Pipeline parameters\n",
    "with open(\"../config.toml\", \"r\") as f:\n",
    "    config = tomlkit.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "# Directories\n",
    "ROOT_DIR = config[\"basic\"][\"ANALYSIS_DIR\"]\n",
    "DIR_SAVE = path.join(ROOT_DIR, config[\"basic\"][\"DIR_SAVE\"])\n",
    "DIR_samples = config[\"basic\"][\"DIR_SAMPLES\"]\n",
    "\n",
    "# Basic information\n",
    "TECHNOLOGY: str = config[\"basic\"][\"TECHNOLOGY\"]\n",
    "ORGANISM: str = config[\"basic\"][\"ORGANISM\"]\n",
    "AUTODISCOVER: bool = config[\"basic\"][\"auto_find\"]\n",
    "samples: Dict[str, str] = config[\"basic\"][\"samples\"]\n",
    "\n",
    "sample_components = inputs[TECHNOLOGY][\"files\"]\n",
    "black_list = inputs[TECHNOLOGY][\"black_list\"]\n",
    "read_function = inputs[TECHNOLOGY][\"function\"]\n",
    "raw_name = inputs[TECHNOLOGY][\"raw_name\"]\n",
    "\n",
    "\n",
    "MAX_ONLY: list[str] = [\"pct_counts_mt\", \"pct_counts_rb\", \"pct_counts_hb\"]\n",
    "LOG_TRANSFORMED: list[str] = [\"total_counts\", \"n_genes_by_counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "# Keys\n",
    "\n",
    "plotting_qc_keys = get_keys(qc_dict)\n",
    "\n",
    "if len(get_keys(qc_dict)) == 0:\n",
    "    raise ValueError(\"Couldn't get valid qc variables from QC dict.\")\n",
    "\n",
    "filter_qc_keys = plotting_qc_keys\n",
    "\n",
    "plotting_qc_keys = plotting_qc_keys + [\"pct_counts_rb\"]\n",
    "\n",
    "if FILTER_DOUBLETS and \"doublet_score\" not in plotting_qc_keys:\n",
    "    plotting_qc_keys = plotting_qc_keys + [\"doublet_score\"]\n",
    "\n",
    "if CORRECT_AMBIENT_RNA and \"decontX_contamination\" not in plotting_qc_keys:\n",
    "    plotting_qc_keys = plotting_qc_keys + [\"decontX_contamination\"]\n",
    "\n",
    "if CELL_CYCLE_SCORE and \"S_score\" not in plotting_qc_keys:\n",
    "    plotting_qc_keys = plotting_qc_keys + [\"S_score\"]\n",
    "\n",
    "if CELL_CYCLE_SCORE and \"G2M_score\" not in plotting_qc_keys:\n",
    "    plotting_qc_keys += [\"G2M_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "# Diagnosic pipeline\n",
    "## Reading files\n",
    "\n",
    "# TODO: Refactor to a better design, use a custom function for discovery.\n",
    "if AUTODISCOVER and len(samples) == 0:\n",
    "    files = walk(DIR_samples)\n",
    "    for root, dir, files in files:\n",
    "        if (\n",
    "            len(set(sample_components).difference(set(files))) == 0\n",
    "            and path.basename(root) != raw_name\n",
    "        ):\n",
    "            samples[get_sample_name(root, black_list, 5)] = root\n",
    "else:\n",
    "    samples = config[\"basic\"][\"samples\"]\n",
    "    if len(samples) == 0:\n",
    "        raise RuntimeError(\n",
    "            \"No samples paths were provided, provide sample paths as a dictionary in 'config.toml'\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | warning: false\n",
    "itables.show(pd.DataFrame(samples, index=[\"sample path\"]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "adatas = {}\n",
    "raw_h5 = {}\n",
    "for sample_id, filename in samples.items():\n",
    "    sample_adata = read_function(filename)\n",
    "    sample_adata.var_names_make_unique()\n",
    "    adatas[sample_id] = sample_adata\n",
    "\n",
    "\n",
    "if TECHNOLOGY == \"10x\" and CORRECT_AMBIENT_RNA:\n",
    "    for sample_id, filename in samples.items():\n",
    "        files = listdir(path.dirname(filename))\n",
    "        raw_file = [\n",
    "            file for file in files if \"raw_feature_bc_matrix\" in file and \".h5\" in file\n",
    "        ]\n",
    "        if len(raw_file) == 1:\n",
    "            adata_raw = sc.read_10x_h5(path.join(path.dirname(filename), raw_file[0]))\n",
    "        else:\n",
    "            raise ValueError(\"No/Multiple raw files meeting condition were found\")\n",
    "\n",
    "        adata_raw.var_names_make_unique()\n",
    "        raw_h5[sample_id] = adata_raw\n",
    "\n",
    "\n",
    "adata = ad.concat(adatas, label=\"sample\", join=\"outer\", merge=\"same\")\n",
    "adata.obs_names_make_unique()\n",
    "del samples\n",
    "\n",
    "if QC_PER_SAMPLE and TECHNOLOGY == \"10x\" and CORRECT_AMBIENT_RNA:\n",
    "    adata_raw = ad.concat(raw_h5, label=\"sample\", join=\"outer\", merge=\"same\")\n",
    "    adata_raw.obs_names_make_unique()\n",
    "    del raw_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs  n_vars = 31087  36601\n",
       "    obs: 'sample', 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_20_genes', 'total_counts_mt', 'log1p_total_counts_mt', 'pct_counts_mt', 'total_counts_rb', 'log1p_total_counts_rb', 'pct_counts_rb', 'total_counts_hb', 'log1p_total_counts_hb', 'pct_counts_hb', 'n_genes_by_counts_outlier', 'total_counts_outlier', 'pct_counts_mt_outlier', 'outlier', 'S_score', 'G2M_score', 'phase', 'groups', 'leiden_1.0', 'scTAB_annotation', 'scTAB_annotation_majority_voting'\n",
       "    var: 'gene_ids', 'feature_types', 'mt', 'rb', 'hb', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'mean', 'std', 'highly_variable', 'highly_variable_rank', 'means', 'variances', 'variances_norm'\n",
       "    uns: 'CLUSTERING_COL', 'FINAL_CLUSTERED', 'groups', 'hvg', 'leiden_0.1', 'leiden_0.1_colors', 'leiden_0.2', 'leiden_0.3', 'leiden_0.4', 'leiden_0.5', 'leiden_0.6', 'leiden_0.7', 'leiden_0.7_colors', 'leiden_0.8', 'leiden_0.9', 'leiden_1.0', 'leiden_1.1', 'leiden_1.2', 'leiden_1.3', 'leiden_1.3_colors', 'leiden_1.4', 'leiden_1.5', 'leiden_1.6', 'leiden_1.7', 'leiden_1.8', 'leiden_1.8_colors', 'leiden_1.9', 'leiden_2.0', 'leiden_2.1', 'leiden_2.2', 'leiden_2.3', 'leiden_2.4', 'leiden_2.4_colors', 'leiden_2.5', 'leiden_2.6', 'leiden_2.7', 'leiden_2.8', 'leiden_2.9', 'leiden_2.9_colors', 'log1p', 'neighbors', 'over_clustering', 'pca', 'sample_colors', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    layers: 'counts', 'log_norm'\n",
       "    obsp: 'connectivities', 'distances'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Remove\n",
    "\n",
    "adata = sc.read_h5ad(\"../save/adata.h5ad\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "## Adding quality metrics\n",
    "mt_features = qc_features_rules[ORGANISM][\"mito\"]\n",
    "rb_features = qc_features_rules[ORGANISM][\"ribo\"]\n",
    "hb_features = qc_features_rules[ORGANISM][\"hb\"]\n",
    "\n",
    "\n",
    "# mitochondrial genes, \"MT-\" for human, \"Mt-\" for mouse\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(tuple(mt_features))\n",
    "# ribosomal genes\n",
    "adata.var[\"rb\"] = adata.var_names.str.startswith(tuple(rb_features))\n",
    "# hemoglobin genes\n",
    "adata.var[\"hb\"] = adata.var_names.str.contains(\n",
    "    tuple(hb_features)[0]\n",
    ")  # Only regex is accepted\n",
    "\n",
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=[\"mt\", \"rb\", \"hb\"], percent_top=[20], inplace=True, log1p=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "if all(map(lambda x: isinstance(x, (list, Number)), qc_dict.values())):\n",
    "    compute_outliers_bulk(adata, qc_dict)\n",
    "elif all(map(lambda x: isinstance(x, dict), qc_dict.values())):\n",
    "    compute_outlier_sample(adata, qc_dict)\n",
    "else:\n",
    "    raise ValueError(\"Please provide a QC-Dict in a valid format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "## Ambient RNA correction\n",
    "## TODO: Check if the Ambient RNA can be improved by using Batch information?\n",
    "\n",
    "if CORRECT_AMBIENT_RNA and TECHNOLOGY == \"10x\":\n",
    "    import tempfile\n",
    "    import urllib.request\n",
    "    from os import path, remove, system\n",
    "\n",
    "    with tempfile.TemporaryDirectory(dir=\".\") as tmpdirname:\n",
    "        # Workaround failure to install GenomeInfoDbData using pixi\n",
    "        dn_path = path.join(tmpdirname, \"GenomeInfoDbData_1.2.11.tar.gz\")\n",
    "        dn_url = \"https://bioconductor.org/packages/3.18/data/annotation/src/contrib/GenomeInfoDbData_1.2.11.tar.gz\"\n",
    "        urllib.request.urlretrieve(dn_url, filename=dn_path)\n",
    "        system(f\"R CMD INSTALL {dn_path}\")\n",
    "\n",
    "        # Define paths for temporary files\n",
    "        sce_path = path.join(tmpdirname, \"sce.h5ad\")\n",
    "        raw_path = path.join(tmpdirname, \"raw.h5ad\")\n",
    "        decontx_path = path.join(tmpdirname, \"decontX.h5ad\")\n",
    "\n",
    "        # Save adata and adata_raw to the temporary directory\n",
    "        adata.write_h5ad(sce_path)\n",
    "        adata_raw.write_h5ad(raw_path)\n",
    "\n",
    "        # Execute R scripts with temporary file paths\n",
    "        system(\n",
    "            f\"Rscript ./utils/deconx.R -s {sce_path} -r {raw_path} -o {decontx_path}\"\n",
    "        )\n",
    "\n",
    "        # Read the result back from the temporary directory\n",
    "        adata = sc.read_h5ad(decontx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "## Doublet Detection\n",
    "\n",
    "# TODO: Check real-life performance\n",
    "# TODO: Check Interop with R to convert object to R & vice-versa\n",
    "if FILTER_DOUBLETS and TECHNOLOGY == \"10x\":\n",
    "    sc.pp.scrublet(adata, batch_key=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "## Cell cycle Scoring\n",
    "# **Not reliable, do via interop later**\n",
    "\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.scale(adata)\n",
    "\n",
    "\n",
    "if CELL_CYCLE_SCORE:\n",
    "    if ORGANISM in [\"human\", \"mouse\"]:\n",
    "        s_genes = [x.strip() for x in open(\"../resources/s_genes.txt\")]\n",
    "        g2m_genes = [x.strip() for x in open(\"../resources/s_genes.txt\")]\n",
    "\n",
    "        if ORGANISM == \"mouse\":\n",
    "            s_genes = human2mouse(s_genes)\n",
    "            g2m_genes = human2mouse(g2m_genes)\n",
    "\n",
    "        # Cell cycle scoring is not reliable and not similair to Seurat\n",
    "        sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)\n",
    "    else:\n",
    "        logging.error(\"Organism must be either human or mouse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnostic Plots (prior to filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic QC plots & metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 2\n",
    "nrows = len(plotting_qc_keys) // ncols + len(plotting_qc_keys) % ncols\n",
    "\n",
    "figsize = 3\n",
    "wspace = 0.5\n",
    "hspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(\n",
    "        ncols * figsize + figsize * wspace * (ncols - 1),\n",
    "        nrows * figsize + hspace * (nrows - 1),\n",
    "    ),\n",
    ")\n",
    "plt.subplots_adjust(wspace=wspace, hspace=hspace)\n",
    "\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Prevent the subplots from showing\n",
    "plt.close(fig)\n",
    "\n",
    "for i, key in enumerate(plotting_qc_keys):\n",
    "    sc.pl.violin(\n",
    "        adata, keys=[key], groupby=\"sample\", stripplot=False, inner=\"box\", ax=axs[i]\n",
    "    )\n",
    "    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if len(plotting_qc_keys) < nrows * ncols:\n",
    "    for i in range(len(plotting_qc_keys), nrows * ncols):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of basic QC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = adata.obs.groupby(\"sample\")[plotting_qc_keys].agg([\"mean\", \"median\"]).round(3)\n",
    "df2 = adata.obs.groupby(\"sample\")[[\"sample\"]].agg([\"size\"])\n",
    "itables.show(pd.concat([df1, df2], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "from operator import add\n",
    "\n",
    "sample_fig_list = []\n",
    "hvplot.extension(\"bokeh\")\n",
    "ls = []\n",
    "df = adata.obs[plotting_qc_keys]\n",
    "for key in df.columns:\n",
    "    fig = (\n",
    "        adata.obs[[key, \"sample\"]]\n",
    "        .hvplot(\n",
    "            kind=\"hist\",\n",
    "            bins=300,\n",
    "            width=400,\n",
    "            height=350,\n",
    "            line_color=\"#A3D5FF\",\n",
    "            bgcolor=\"white\",\n",
    "        )\n",
    "        .opts(axiswise=True)\n",
    "    )\n",
    "    ls.append(fig)\n",
    "\n",
    "layout = reduce(add, ls)\n",
    "layout = layout.cols(2)\n",
    "sample_fig_list.append((\"All samples\", layout))\n",
    "\n",
    "samples = adata.obs[\"sample\"].unique()\n",
    "samples = np.sort(samples)\n",
    "for sample in samples:\n",
    "    ls = []\n",
    "    df = adata.obs.loc[adata.obs[\"sample\"] == sample, plotting_qc_keys]\n",
    "    for key in df.columns:\n",
    "        fig = (\n",
    "            df[[key]]\n",
    "            .hvplot(\n",
    "                kind=\"hist\",\n",
    "                bins=300,\n",
    "                width=400,\n",
    "                height=350,\n",
    "                line_color=\"#A3D5FF\",\n",
    "                bgcolor=\"white\",\n",
    "            )\n",
    "            .opts(axiswise=True)\n",
    "        )\n",
    "        ls.append(fig)\n",
    "    layout = reduce(add, ls)\n",
    "    layout = layout.cols(2)\n",
    "    sample_fig_list.append((sample, layout))\n",
    "\n",
    "\n",
    "pn.Tabs(*sample_fig_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "import holoviews as hv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "n = len(plotting_qc_keys)\n",
    "ncols = 2\n",
    "nrows = n // ncols + (n % ncols > 0)\n",
    "\n",
    "\n",
    "quarto_markdown = \"::: {.panel-tabset}\\n\\n\"\n",
    "\n",
    "\n",
    "# Create the subplots\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(\n",
    "        ncols * figsize + figsize * wspace * (ncols - 1),\n",
    "        nrows * figsize + wspace * (nrows - 1),\n",
    "    ),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "# Flatten the axes\n",
    "axs = axs.flatten()\n",
    "outlier_dict = {}\n",
    "\n",
    "# Plot a histogram on each subplot\n",
    "for i, col in enumerate(plotting_qc_keys):\n",
    "    sns.histplot(data=df, x=col, ax=axs[i], bins=300)\n",
    "\n",
    "# Remove any unused subplots\n",
    "if len(df.columns) < nrows * ncols:\n",
    "    for i in range(len(df.columns), nrows * ncols):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "buf = io.BytesIO()\n",
    "plt.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "buf.seek(0)\n",
    "# Encode the image to base64\n",
    "img_str = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "# Add the image to the markdown\n",
    "quarto_markdown += (\n",
    "    f\"### All samples \\n\\n![All samples](data:image/png;base64,{img_str})\\n\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "samples = adata.obs[\"sample\"].unique()\n",
    "samples = np.sort(samples)\n",
    "for sample in samples:\n",
    "    ls = []\n",
    "    df = adata.obs.loc[adata.obs[\"sample\"] == sample, plotting_qc_keys]\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        figsize=(\n",
    "            ncols * figsize + figsize * wspace * (ncols - 1),\n",
    "            nrows * figsize + wspace * (nrows - 1),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "\n",
    "    # Flatten the axes\n",
    "    axs = axs.flatten()\n",
    "    outlier_dict = {}\n",
    "\n",
    "    # Plot a histogram on each subplot\n",
    "    for i, col in enumerate(plotting_qc_keys):\n",
    "        sns.histplot(data=df, x=col, ax=axs[i], bins=300)\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    if len(df.columns) < nrows * ncols:\n",
    "        for i in range(len(df.columns), nrows * ncols):\n",
    "            fig.delaxes(axs[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    # Encode the image to base64\n",
    "    img_str = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    # Add the image to the markdown\n",
    "    quarto_markdown += (\n",
    "        f\"### {sample} \\n\\n![{sample}](data:image/png;base64,{img_str})\\n\\n\"\n",
    "    )\n",
    "\n",
    "quarto_markdown += \":::\\n\"\n",
    "# Display the generated markdown\n",
    "display(Markdown(quarto_markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots of confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = adata.obs[plotting_qc_keys + [\"sample\"]]\n",
    "\n",
    "# Determine the number of rows and columns for your subplot grid\n",
    "n = len(df.columns)\n",
    "ncols = 2\n",
    "nrows = n // ncols\n",
    "figwidth = 5\n",
    "figheight = 4\n",
    "\n",
    "# Create the subplots\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(\n",
    "        ncols * figwidth + figwidth * wspace * (ncols - 1),\n",
    "        nrows * figheight + wspace * (nrows - 1),\n",
    "    ),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "\n",
    "# Flatten the axes\n",
    "axs = axs.flatten()\n",
    "\n",
    "sns.scatterplot(\n",
    "    df, x=\"total_counts\", y=\"n_genes_by_counts\", hue=\"sample\", alpha=0.4, s=6, ax=axs[0]\n",
    ")\n",
    "axs[0].legend(fancybox=True, framealpha=0.8)\n",
    "sns.scatterplot(\n",
    "    df, x=\"total_counts\", y=\"pct_counts_mt\", hue=\"sample\", alpha=0.4, s=6, ax=axs[1]\n",
    ")\n",
    "axs[1].legend(fancybox=True, framealpha=0.8)\n",
    "sns.scatterplot(\n",
    "    df, x=\"total_counts\", y=\"pct_counts_rb\", hue=\"sample\", alpha=0.4, s=6, ax=axs[2]\n",
    ")\n",
    "axs[2].legend(fancybox=True, framealpha=0.8)\n",
    "sns.move_legend(axs[0], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "sns.move_legend(axs[1], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "sns.move_legend(axs[2], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "if FILTER_DOUBLETS:\n",
    "    sns.scatterplot(\n",
    "        df, x=\"total_counts\", y=\"doublet_score\", hue=\"sample\", alpha=0.4, s=6, ax=axs[3]\n",
    "    )\n",
    "    sns.move_legend(axs[3], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "if CORRECT_AMBIENT_RNA:\n",
    "    sns.scatterplot(\n",
    "        df,\n",
    "        x=\"total_counts\",\n",
    "        y=\"decontX_contamination\",\n",
    "        hue=\"sample\",\n",
    "        alpha=0.4,\n",
    "        s=6,\n",
    "        ax=axs[4],\n",
    "    )\n",
    "    sns.move_legend(axs[4], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "[fig.delaxes(ax) for ax in axs.flatten() if not ax.has_data()]\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeconX contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "if CORRECT_AMBIENT_RNA and TECHNOLOGY == \"10x\":\n",
    "    ax1 = pw.Brick(figsize=(6, 6))\n",
    "    ax2 = pw.Brick(figsize=(6, 6))\n",
    "\n",
    "    scatter = sns.scatterplot(\n",
    "        pd.concat([adata.obsm[\"decontX_UMAP\"], adata.obs], axis=1),\n",
    "        x=\"DecontX_UMAP_1\",\n",
    "        y=\"DecontX_UMAP_2\",\n",
    "        hue=\"decontX_contamination\",\n",
    "        s=0.8,\n",
    "        ax=ax1,\n",
    "        palette=\"inferno\",\n",
    "    )\n",
    "    sns.move_legend(\n",
    "        scatter, \"center right\", bbox_to_anchor=(1.1, 0.5), title=None, frameon=False\n",
    "    )\n",
    "\n",
    "    scatter = sns.scatterplot(\n",
    "        pd.concat([adata.obsm[\"decontX_UMAP\"], adata.obs], axis=1),\n",
    "        x=\"DecontX_UMAP_1\",\n",
    "        y=\"DecontX_UMAP_2\",\n",
    "        hue=\"decontX_clusters\",\n",
    "        s=0.8,\n",
    "        ax=ax2,\n",
    "    )\n",
    "    sns.move_legend(\n",
    "        scatter, \"center right\", bbox_to_anchor=(1.15, 0.5), title=None, frameon=False\n",
    "    )\n",
    "\n",
    "    ax12 = ax1 + ax2\n",
    "    display(ax12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effects of confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "sc.pp.pca(adata, n_comps=30)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.leiden(adata, key_added=\"groups\", flavor=\"leidenalg\")\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "figs = sc.pl.umap(\n",
    "    adata,\n",
    "    size=7,\n",
    "    color=[\"sample\"] + plotting_qc_keys,\n",
    "    show=False,\n",
    "    ncols=2,\n",
    "    color_map=\"inferno\",\n",
    "    sort_order=False,\n",
    "    alpha=0.8,\n",
    "    hspace=0.2,\n",
    "    wspace=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "ls = {}\n",
    "for key in filter_qc_keys:\n",
    "    ls[key] = (\n",
    "        adata.obs.query(f\"{key}_outlier == False\").groupby(\"sample\")[key].agg(\"min\")\n",
    "    )\n",
    "min_df = pd.concat(ls, axis=1)\n",
    "\n",
    "for key in filter_qc_keys:\n",
    "    ls[key] = (\n",
    "        adata.obs.query(f\"{key}_outlier == False\").groupby(\"sample\")[key].agg(\"max\")\n",
    "    )\n",
    "max_df = pd.concat(ls, axis=1)\n",
    "\n",
    "pd.concat([min_df, max_df], keys=[\"min\", \"max\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of outliers based on provided criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "# TODO: Fix\n",
    "df_l = []\n",
    "col_l = []\n",
    "for key in filter_qc_keys:\n",
    "    try:\n",
    "        df_l.append(\n",
    "            pd.DataFrame(\n",
    "                adata.obs[[f\"{key}_outlier\", \"sample\"]].value_counts().loc[(True), :]\n",
    "            )\n",
    "        )\n",
    "        col_l.append(f\"{key}_outlier\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "col_l.append(f\"aggregate outliers\")\n",
    "df_l.append(\n",
    "    pd.DataFrame(adata.obs[[f\"outlier\", \"sample\"]].value_counts().loc[(True), :])\n",
    ")\n",
    "\n",
    "df_l.append(pd.DataFrame(adata.obs[[\"sample\"]].value_counts()))\n",
    "df_l[-1].index = df_l[-1].index.get_level_values(0)\n",
    "col_l.append(f\"Total Cells\")\n",
    "\n",
    "df = pd.concat(df_l, axis=1)\n",
    "df.columns = [col_l]\n",
    "df = df.loc[np.sort(df.index), :]\n",
    "itables.show(df.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell filtering based on outlier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "adata.obs = adata.obs.infer_objects()\n",
    "\n",
    "# Saving The object at the last step before subsseting\n",
    "if path.exists(DIR_SAVE):\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"raw_adata.h5ad\"))\n",
    "else:\n",
    "    mkdir(DIR_SAVE)\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"raw_adata.h5ad\"))\n",
    "\n",
    "# Cell Filtering based on threshold\n",
    "\n",
    "\n",
    "adata = adata[(~adata.obs.outlier)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC plots (post filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of basic QC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "df1 = adata.obs.groupby(\"sample\")[plotting_qc_keys].agg([\"mean\", \"median\"]).round(3)\n",
    "df2 = adata.obs.groupby(\"sample\")[[\"sample\"]].agg([\"size\"])\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "from operator import add\n",
    "\n",
    "sample_fig_list = []\n",
    "hvplot.extension(\"bokeh\")\n",
    "ls = []\n",
    "df = adata.obs[plotting_qc_keys]\n",
    "for key in df.columns:\n",
    "    fig = (\n",
    "        adata.obs[[key, \"sample\"]]\n",
    "        .hvplot(\n",
    "            kind=\"hist\",\n",
    "            bins=300,\n",
    "            width=400,\n",
    "            height=350,\n",
    "            line_color=\"#A3D5FF\",\n",
    "            bgcolor=\"white\",\n",
    "        )\n",
    "        .opts(axiswise=True)\n",
    "    )\n",
    "    ls.append(fig)\n",
    "\n",
    "layout = reduce(add, ls)\n",
    "layout = layout.cols(2)\n",
    "sample_fig_list.append((\"All samples\", layout))\n",
    "\n",
    "samples = adata.obs[\"sample\"].unique()\n",
    "samples = np.sort(samples)\n",
    "for sample in samples:\n",
    "    ls = []\n",
    "    df = adata.obs.loc[adata.obs[\"sample\"] == sample, plotting_qc_keys]\n",
    "    for key in df.columns:\n",
    "        fig = (\n",
    "            df[[key]]\n",
    "            .hvplot(\n",
    "                kind=\"hist\",\n",
    "                bins=300,\n",
    "                width=400,\n",
    "                height=350,\n",
    "                line_color=\"#A3D5FF\",\n",
    "                bgcolor=\"white\",\n",
    "            )\n",
    "            .opts(axiswise=True)\n",
    "        )\n",
    "        ls.append(fig)\n",
    "    layout = reduce(add, ls)\n",
    "    layout = layout.cols(2)\n",
    "    sample_fig_list.append((sample, layout))\n",
    "\n",
    "\n",
    "pn.Tabs(*sample_fig_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "import holoviews as hv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "df = adata.obs[plotting_qc_keys]\n",
    "\n",
    "\n",
    "n = len(plotting_qc_keys)\n",
    "ncols = 2\n",
    "nrows = n // ncols + (n % ncols > 0)\n",
    "\n",
    "\n",
    "quarto_markdown = \"::: {.panel-tabset}\\n\\n\"\n",
    "\n",
    "\n",
    "# Create the subplots\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(\n",
    "        ncols * figsize + figsize * wspace * (ncols - 1),\n",
    "        nrows * figsize + wspace * (nrows - 1),\n",
    "    ),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "# Flatten the axes\n",
    "axs = axs.flatten()\n",
    "outlier_dict = {}\n",
    "\n",
    "# Plot a histogram on each subplot\n",
    "for i, col in enumerate(plotting_qc_keys):\n",
    "    sns.histplot(data=df, x=col, ax=axs[i], bins=300)\n",
    "\n",
    "# Remove any unused subplots\n",
    "if len(df.columns) < nrows * ncols:\n",
    "    for i in range(len(df.columns), nrows * ncols):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "buf = io.BytesIO()\n",
    "plt.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "buf.seek(0)\n",
    "# Encode the image to base64\n",
    "img_str = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "# Add the image to the markdown\n",
    "quarto_markdown += (\n",
    "    f\"### All samples \\n\\n![All samples](data:image/png;base64,{img_str})\\n\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "samples = adata.obs[\"sample\"].unique()\n",
    "samples = np.sort(samples)\n",
    "for sample in samples:\n",
    "    ls = []\n",
    "    df = adata.obs.loc[adata.obs[\"sample\"] == sample, plotting_qc_keys]\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=nrows,\n",
    "        ncols=ncols,\n",
    "        figsize=(\n",
    "            ncols * figsize + figsize * wspace * (ncols - 1),\n",
    "            nrows * figsize + wspace * (nrows - 1),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "\n",
    "    # Flatten the axes\n",
    "    axs = axs.flatten()\n",
    "    outlier_dict = {}\n",
    "\n",
    "    # Plot a histogram on each subplot\n",
    "    for i, col in enumerate(plotting_qc_keys):\n",
    "        sns.histplot(data=df, x=col, ax=axs[i], bins=300)\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    if len(df.columns) < nrows * ncols:\n",
    "        for i in range(len(df.columns), nrows * ncols):\n",
    "            fig.delaxes(axs[i])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format=\"png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    # Encode the image to base64\n",
    "    img_str = base64.b64encode(buf.read()).decode(\"utf-8\")\n",
    "    # Add the image to the markdown\n",
    "    quarto_markdown += (\n",
    "        f\"### {sample} \\n\\n![{sample}](data:image/png;base64,{img_str})\\n\\n\"\n",
    "    )\n",
    "\n",
    "quarto_markdown += \":::\\n\"\n",
    "# Display the generated markdown\n",
    "display(Markdown(quarto_markdown))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots of confounders after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = adata.obs[plotting_qc_keys + [\"sample\"]]\n",
    "\n",
    "# Determine the number of rows and columns for your subplot grid\n",
    "n = len(df.columns)\n",
    "ncols = 2\n",
    "nrows = n // ncols\n",
    "figwidth = 5\n",
    "figheight = 4\n",
    "\n",
    "# Create the subplots\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(\n",
    "        ncols * figwidth + figwidth * wspace * (ncols - 1),\n",
    "        nrows * figheight + wspace * (nrows - 1),\n",
    "    ),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "\n",
    "# Flatten the axes\n",
    "axs = axs.flatten()\n",
    "\n",
    "sns.scatterplot(\n",
    "    df, x=\"total_counts\", y=\"n_genes_by_counts\", hue=\"sample\", alpha=0.4, s=6, ax=axs[0]\n",
    ")\n",
    "axs[0].legend(fancybox=True, framealpha=0.8)\n",
    "sns.scatterplot(\n",
    "    df, x=\"total_counts\", y=\"pct_counts_mt\", hue=\"sample\", alpha=0.4, s=6, ax=axs[1]\n",
    ")\n",
    "axs[1].legend(fancybox=True, framealpha=0.8)\n",
    "sns.scatterplot(\n",
    "    df, x=\"total_counts\", y=\"pct_counts_rb\", hue=\"sample\", alpha=0.4, s=6, ax=axs[2]\n",
    ")\n",
    "axs[2].legend(fancybox=True, framealpha=0.8)\n",
    "sns.move_legend(axs[0], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "sns.move_legend(axs[1], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "sns.move_legend(axs[2], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "if FILTER_DOUBLETS:\n",
    "    sns.scatterplot(\n",
    "        df, x=\"total_counts\", y=\"doublet_score\", hue=\"sample\", alpha=0.4, s=6, ax=axs[3]\n",
    "    )\n",
    "    sns.move_legend(axs[3], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "if CORRECT_AMBIENT_RNA:\n",
    "    sns.scatterplot(\n",
    "        df,\n",
    "        x=\"total_counts\",\n",
    "        y=\"decontX_contamination\",\n",
    "        hue=\"sample\",\n",
    "        alpha=0.4,\n",
    "        s=6,\n",
    "        ax=axs[4],\n",
    "    )\n",
    "    sns.move_legend(axs[4], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "\n",
    "[fig.delaxes(ax) for ax in axs.flatten() if not ax.has_data()]\n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecontX contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "if CORRECT_AMBIENT_RNA and TECHNOLOGY == \"10x\":\n",
    "    ax1 = pw.Brick(figsize=(6, 6))\n",
    "    ax2 = pw.Brick(figsize=(6, 6))\n",
    "\n",
    "    scatter = sns.scatterplot(\n",
    "        pd.concat([adata.obsm[\"decontX_UMAP\"], adata.obs], axis=1),\n",
    "        x=\"DecontX_UMAP_1\",\n",
    "        y=\"DecontX_UMAP_2\",\n",
    "        hue=\"decontX_contamination\",\n",
    "        s=0.8,\n",
    "        ax=ax1,\n",
    "        palette=\"inferno\",\n",
    "    )\n",
    "    sns.move_legend(\n",
    "        scatter, \"center right\", bbox_to_anchor=(1.1, 0.5), title=None, frameon=False\n",
    "    )\n",
    "\n",
    "    scatter = sns.scatterplot(\n",
    "        pd.concat([adata.obsm[\"decontX_UMAP\"], adata.obs], axis=1),\n",
    "        x=\"DecontX_UMAP_1\",\n",
    "        y=\"DecontX_UMAP_2\",\n",
    "        hue=\"decontX_clusters\",\n",
    "        s=0.8,\n",
    "        ax=ax2,\n",
    "    )\n",
    "    sns.move_legend(\n",
    "        scatter, \"center right\", bbox_to_anchor=(1.15, 0.5), title=None, frameon=False\n",
    "    )\n",
    "\n",
    "    ax12 = ax1 + ax2\n",
    "    display(ax12)\n",
    "\n",
    "    # | echo: false\n",
    "# | warning: false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORRECT_AMBIENT_RNA and TECHNOLOGY == \"10x\":\n",
    "    with rc_context(\n",
    "        {\n",
    "            \"figure.figsize\": (\n",
    "                adata.obs[\"decontX_clusters\"].astype(\"int32\").max() * 0.7,\n",
    "                5,\n",
    "            )\n",
    "        }\n",
    "    ):\n",
    "        sns.violinplot(adata.obs, x=\"decontX_clusters\", y=\"decontX_contamination\")\n",
    "        sns.stripplot(\n",
    "            adata.obs, x=\"decontX_clusters\", y=\"decontX_contamination\", s=1, c=\"black\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering after to cell filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "sc.pp.pca(adata, n_comps=30)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.leiden(adata, key_added=\"groups\", flavor=\"leidenalg\")\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "with rc_context({\"figure.figsize\": (5, (len(plotting_qc_keys) + 1) * 0.6)}):\n",
    "    figs = sc.pl.umap(\n",
    "        adata,\n",
    "        size=8,\n",
    "        color=[\"sample\"] + plotting_qc_keys,\n",
    "        show=False,\n",
    "        ncols=2,\n",
    "        color_map=\"inferno\",\n",
    "        sort_order=False,\n",
    "        alpha=0.8,\n",
    "        hspace=0.2,\n",
    "        wspace=0.3,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| echo: false\n",
    "# #| output: false\n",
    "# #| warning: false\n",
    "\n",
    "# ## Regression of Variables\n",
    "\n",
    "# # - [ ] Add error handling if the vars to regress is empty or contain non-keys\n",
    "# if REGRESS:\n",
    "#     sc.pp.regress_out(adata, keys= VARS_TO_REGRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "adata.obs = adata.obs.infer_objects()\n",
    "## Save Result\n",
    "if path.exists(DIR_SAVE):\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))\n",
    "else:\n",
    "    mkdir(DIR_SAVE)\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi - Python 3 (ipykernel)",
   "language": "python",
   "name": "pixi-kernel-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
