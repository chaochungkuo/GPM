{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Normalization & Clustering of scRNA-seq\"\n",
    "author: \"Mohamed Mabrouk\"\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    html-math-method: katex\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "    page-layout: full\n",
    "execute:\n",
    "    echo: true\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "import tomlkit\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "import pandas as pd\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc_context\n",
    "import patchworklib as pw\n",
    "from utils.preprocessing_funcs import get_var_features_num, is_raw_counts\n",
    "from numbers import Number\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "from os import path\n",
    "import session_info\n",
    "import logging\n",
    "from tempfile import TemporaryDirectory\n",
    "from os import system\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: true\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "\"in the following cell, override the default pipeline parameters if needed\"\n",
    "HVG_BY_BATCH = False\n",
    "VARIABLE_FEATURES = 0.1  # a fraction between 0.0 and 1.0 or a number of genes.\n",
    "CLUSTERING_RANGE = [\n",
    "    0.0,\n",
    "    3.0,\n",
    "    0.2,\n",
    "]  # Range of resolution for clustering, (min, max, step).\n",
    "\n",
    "\n",
    "# TODO: Check the best implementation for variable regression\n",
    "# REGRESS_VARIABLES = []  # List: Variables to regress out (default: [])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "## Pipeline parameters\n",
    "with open(\"../config.toml\", \"r\") as f:\n",
    "    config = tomlkit.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "ROOT_DIR = config[\"basic\"][\"ANALYSIS_DIR\"]\n",
    "DIR_SAVE = path.join(ROOT_DIR, config[\"basic\"][\"DIR_SAVE\"])\n",
    "\n",
    "NORMALIZATION_METHOD = config[\"normalization\"][\"NORMALIZATION_METHOD\"]\n",
    "COUNTS_LAYER = config[\"normalization\"][\"COUNTS_LAYER\"]\n",
    "CLUSTERING_COL = config[\"clustering\"][\"CLUSTERING_COL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "adata = sc.read_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (3400234455.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    if isinstance(NORMALIZATION_METHOD, str)\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "from tomlkit.items import String, Array\n",
    "\n",
    "\n",
    "# Getting a stable counts layer to be used later, setting X to be raw count values. \n",
    "if COUNTS_LAYER == \"X\":\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "    COUNTS_LAYER = \"counts\"\n",
    "elif COUNTS_LAYER in adata.layers.keys():\n",
    "    adata.X = adata.layers[COUNTS_LAYER].copy()\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"{COUNTS_LAYER} layer can't be found in the object\"\n",
    "    )\n",
    "\n",
    "\n",
    "var_features = get_var_features_num(adata, VARIABLE_FEATURES)\n",
    "\n",
    "\n",
    "#BUG: No stable counts slot, reach to the counts slot. \n",
    "def normalize_adata(adata: AnnData, normalization_method: String, counts_layer:str) -> None:\n",
    "\n",
    "    if normalization_method not in [\"log_norm\", \"p_residuals\"]:\n",
    "        raise ValueError(\"Invalid normalization method, only 'log_norm' and 'p_residuals' are supported.\")\n",
    "    \n",
    "\n",
    "    if normalization_method == \"log_norm\":\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "        adata.layers[\"log_norm\"] = adata.X.copy()\n",
    "\n",
    "        # https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.highly_variable_genes.html\n",
    "        # Similair to Seurat FindVariableFeatures(method='vst')\n",
    "        if HVG_BY_BATCH:\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata, n_top_genes=var_features, batch_key=\"sample\", flavor=\"seurat_v3\"\n",
    "            )\n",
    "        else:\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata, n_top_genes=var_features, batch_key=None, flavor=\"seurat_v3\"\n",
    "            )\n",
    "\n",
    "    if normalization_method == \"p_residuals\":\n",
    "        # Recipie for variable feature selection, pearson normalization, and PCA\n",
    "        adata = sc.experimental.pp.recipe_pearson_residuals(\n",
    "            adata=adata, n_top_genes=var_features\n",
    "        )\n",
    "        adata[\"p_residuals\"] = adata.X.copy()\n",
    "\n",
    "\n",
    "normalize_adata(adata, NORMALIZATION_METHOD, COUNTS_LAYER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Variable Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "print(f\"number of variable genes is: {var_features}\")\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "sc.pp.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "assert len(CLUSTERING_RANGE) == 3\n",
    "assert all([isinstance(i, Number) for i in CLUSTERING_RANGE])\n",
    "\n",
    "# If the min_range is 0, skip the first round and start from 0 + step.\n",
    "min_range = (\n",
    "    CLUSTERING_RANGE[0]\n",
    "    if CLUSTERING_RANGE[0] > 0\n",
    "    else CLUSTERING_RANGE[0] + CLUSTERING_RANGE[2]\n",
    ")\n",
    "max_range = CLUSTERING_RANGE[1]\n",
    "step = CLUSTERING_RANGE[2]\n",
    "\n",
    "for i in np.arange(min_range, max_range, step):\n",
    "    resolution = np.around(i, decimals=3)\n",
    "    sc.tl.leiden(adata=adata, key_added=f\"leiden_{resolution}\", resolution=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "with TemporaryDirectory(dir=\".\") as f:\n",
    "    input_dir = path.join(f, \"leiden_clusters.csv\")\n",
    "    df = adata.obs.filter(regex=\"leiden_\")\n",
    "    df.to_csv(input_dir)\n",
    "    system(f\"Rscript ./utils/clustree.R -i {input_dir} -p leiden_ -o {f}\")\n",
    "    fig = plt.imread(path.join(f, \"clustree.png\"))\n",
    "\n",
    "with rc_context({\"figure.figsize\": (10, 10)}):\n",
    "    plt.imshow(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "# Source: https://evafast.github.io/blog/2019/06/28/example_content/\n",
    "\n",
    "ig_obj = sc.Neighbors(adata).to_igraph()\n",
    "results_df = pd.DataFrame(\n",
    "    columns=[\"resolution\", \"number_of_clusters\", \"modularity\", \"davies_bouldin_score\"]\n",
    ")\n",
    "\n",
    "for col in adata.obs.filter(regex=\"leiden_\").columns:\n",
    "    modularity_index = ig_obj.modularity(adata.obs[col].values.astype(\"int32\"))\n",
    "    davies_bouldin_avg = davies_bouldin_score(adata.obsm[\"X_pca\"], adata.obs[col])\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                col,\n",
    "                max(adata.obs[col].values.astype(\"int32\")),\n",
    "                davies_bouldin_avg,\n",
    "                modularity_index,\n",
    "            ]\n",
    "        ],\n",
    "        columns=[\n",
    "            \"resolution\",\n",
    "            \"number_of_clusters\",\n",
    "            \"davies_bouldin_score\",\n",
    "            \"modularity\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    results_df = pd.concat([results_df, df])\n",
    "results_df = results_df.reset_index()\n",
    "\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "g = (\n",
    "    so.Plot(results_df, \"resolution\", \"modularity\", text=\"number_of_clusters\")\n",
    "    .add(so.Line())\n",
    "    .add(so.Text(), so.Shift(x=0.0, y=0.0025))\n",
    ").theme({\"figure.figsize\": (10, 7)})\n",
    "\n",
    "fig = g.plot()._figure\n",
    "fig.axes[0].set_xticklabels(fig.axes[0].get_xticklabels(), rotation=45)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "g = (\n",
    "    so.Plot(results_df, \"resolution\", \"davies_bouldin_score\", text=\"number_of_clusters\")\n",
    "    .add(so.Line())\n",
    "    .add(so.Text(), so.Shift(x=0.0, y=0.025))\n",
    ").theme({\"figure.figsize\": (10, 7)})\n",
    "\n",
    "fig = g.plot()._figure\n",
    "fig.axes[0].set_xticklabels(fig.axes[0].get_xticklabels(), rotation=45)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing all clustering solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "with rc_context({\"figure.figsize\": (6, 6)}):\n",
    "    sc.pl.umap(adata, color=adata.obs.filter(regex=\"leiden_\").columns, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "# Over-ride the final clustering col\n",
    "# CLUSTERING_COL = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "if len(CLUSTERING_COL) > 0:\n",
    "    adata.uns[\"CLUSTERING_COL\"] = CLUSTERING_COL\n",
    "else:\n",
    "    adata.uns[\"FINAL_RESOLUTION\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "adata.write_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
