{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Normalization & Clustering of scRNA-seq\"\n",
    "author: \"Mohamed Mabrouk\"\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    html-math-method: katex\n",
    "    code-fold: true\n",
    "    embed-resources: true\n",
    "    page-layout: full\n",
    "execute:\n",
    "    echo: true\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "import tomlkit\n",
    "import scanpy as sc\n",
    "from anndata import AnnData\n",
    "import pandas as pd\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc_context\n",
    "import patchworklib as pw\n",
    "from utils.preprocessing_funcs import (\n",
    "    get_var_features_num,\n",
    "    select_n_uniform,\n",
    ")\n",
    "from numbers import Number\n",
    "\n",
    "\n",
    "import itables\n",
    "from os import path\n",
    "import session_info\n",
    "import logging\n",
    "from tempfile import TemporaryDirectory\n",
    "from os import system\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: true\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "\"in the following cell, override the default pipeline parameters if needed\"\n",
    "HVG_BY_BATCH = False\n",
    "VARIABLE_FEATURES = 0.1  # a fraction between 0.0 and 1.0 or a number of genes.\n",
    "CLUSTERING_RANGE = [\n",
    "    0.0,\n",
    "    3.0,\n",
    "    0.1,\n",
    "]  # Range of resolution for clustering, (min, max, step).\n",
    "\n",
    "\n",
    "# TODO: Check the best implementation for variable regression\n",
    "# REGRESS_VARIABLES = []  # List: Variables to regress out (default: [])."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "## Pipeline parameters\n",
    "with open(\"../config.toml\", \"r\") as f:\n",
    "    config = tomlkit.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "ROOT_DIR = config[\"basic\"][\"ANALYSIS_DIR\"]\n",
    "DIR_SAVE = path.join(ROOT_DIR, config[\"basic\"][\"DIR_SAVE\"])\n",
    "\n",
    "NORMALIZATION_METHOD = config[\"normalization\"][\"NORMALIZATION_METHOD\"]\n",
    "COUNTS_LAYER = config[\"normalization\"][\"COUNTS_LAYER\"]\n",
    "CLUSTERING_COL = config[\"clustering\"][\"CLUSTERING_COL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "adata = sc.read_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.drop(\n",
    "    columns=[col for col in adata.obs.columns if \"leiden\" in col],\n",
    "    errors=\"ignore\",\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "from tomlkit.items import String, Array\n",
    "\n",
    "\n",
    "# Getting a stable counts layer to be used later, setting X to be raw count values.\n",
    "if COUNTS_LAYER == \"X\":\n",
    "    adata.layers[\"counts\"] = adata.X.copy()\n",
    "    COUNTS_LAYER = \"counts\"\n",
    "elif COUNTS_LAYER in adata.layers.keys():\n",
    "    adata.X = adata.layers[COUNTS_LAYER].copy()\n",
    "else:\n",
    "    raise ValueError(\"{COUNTS_LAYER} layer can't be found in the object\")\n",
    "\n",
    "\n",
    "var_features = get_var_features_num(adata, VARIABLE_FEATURES)\n",
    "\n",
    "\n",
    "# BUG: No stable counts slot, reach to the counts slot.\n",
    "def normalize_adata(\n",
    "    adata: AnnData, normalization_method: String, counts_layer: str\n",
    ") -> None:\n",
    "\n",
    "    if normalization_method not in [\"log_norm\", \"p_residuals\"]:\n",
    "        raise ValueError(\n",
    "            \"Invalid normalization method, only 'log_norm' and 'p_residuals' are supported.\"\n",
    "        )\n",
    "\n",
    "    if normalization_method == \"log_norm\":\n",
    "        sc.pp.normalize_total(adata)\n",
    "        sc.pp.log1p(adata)\n",
    "        adata.layers[\"log_norm\"] = adata.X.copy()\n",
    "\n",
    "        # https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.highly_variable_genes.html\n",
    "        # Similair to Seurat FindVariableFeatures(method='vst')\n",
    "        if HVG_BY_BATCH:\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata, n_top_genes=var_features, batch_key=\"sample\", flavor=\"seurat_v3\"\n",
    "            )\n",
    "        else:\n",
    "            sc.pp.highly_variable_genes(\n",
    "                adata, n_top_genes=var_features, batch_key=None, flavor=\"seurat_v3\"\n",
    "            )\n",
    "\n",
    "    if normalization_method == \"p_residuals\":\n",
    "        # Recipie for variable feature selection, pearson normalization, and PCA\n",
    "        adata = sc.experimental.pp.recipe_pearson_residuals(\n",
    "            adata=adata, n_top_genes=var_features\n",
    "        )\n",
    "        adata[\"p_residuals\"] = adata.X.copy()\n",
    "\n",
    "\n",
    "normalize_adata(adata, NORMALIZATION_METHOD, COUNTS_LAYER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select Variable Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "print(f\"number of variable genes is: {var_features}\")\n",
    "sc.pl.highly_variable_genes(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "sc.pp.pca(adata)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.umap(adata)\n",
    "sc.pl.umap(adata, color=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "clustering_keys_added = []\n",
    "\n",
    "assert len(CLUSTERING_RANGE) == 3\n",
    "assert all([isinstance(i, Number) for i in CLUSTERING_RANGE])\n",
    "\n",
    "# If the min_range is 0, skip the first round and start from 0 + step.\n",
    "min_range = (\n",
    "    CLUSTERING_RANGE[0]\n",
    "    if CLUSTERING_RANGE[0] > 0\n",
    "    else CLUSTERING_RANGE[0] + CLUSTERING_RANGE[2]\n",
    ")\n",
    "max_range = CLUSTERING_RANGE[1]\n",
    "step = CLUSTERING_RANGE[2]\n",
    "\n",
    "for i in np.arange(min_range, max_range, step):\n",
    "    resolution = np.around(i, decimals=3)\n",
    "    sc.tl.leiden(adata=adata, key_added=f\"leiden_{resolution}\", resolution=resolution)\n",
    "    clustering_keys_added.append(f\"leiden_{resolution}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "with TemporaryDirectory(dir=\".\") as f:\n",
    "    input_dir = path.join(f, \"leiden_clusters.csv\")\n",
    "    df = adata.obs.filter(regex=\"leiden_\")\n",
    "    df.to_csv(input_dir)\n",
    "    system(f\"Rscript ./utils/clustree.R -i {input_dir} -p leiden_ -o {f}\")\n",
    "    fig = plt.imread(path.join(f, \"clustree.png\"))\n",
    "\n",
    "with rc_context({\"figure.figsize\": (10, 10)}):\n",
    "    plt.imshow(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "# Source: https://evafast.github.io/blog/2019/06/28/example_content/\n",
    "\n",
    "ig_obj = sc.Neighbors(adata).to_igraph()\n",
    "results_df = pd.DataFrame(\n",
    "    columns=[\"resolution\", \"number_of_clusters\", \"modularity\", \"davies_bouldin_score\"]\n",
    ")\n",
    "\n",
    "for col in adata.obs.filter(regex=\"leiden_\").columns:\n",
    "    modularity_index = ig_obj.modularity(adata.obs[col].values.astype(\"int32\"))\n",
    "    davies_bouldin_avg = davies_bouldin_score(adata.obsm[\"X_pca\"], adata.obs[col])\n",
    "    df = pd.DataFrame(\n",
    "        [\n",
    "            [\n",
    "                col,\n",
    "                max(adata.obs[col].values.astype(\"int32\")),\n",
    "                davies_bouldin_avg,\n",
    "                modularity_index,\n",
    "            ]\n",
    "        ],\n",
    "        columns=[\n",
    "            \"resolution\",\n",
    "            \"number_of_clusters\",\n",
    "            \"davies_bouldin_score\",\n",
    "            \"modularity\",\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    results_df = pd.concat([results_df, df])\n",
    "results_df = results_df.reset_index()\n",
    "\n",
    "\n",
    "itables.show(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "g = (\n",
    "    so.Plot(results_df, \"resolution\", \"modularity\", text=\"number_of_clusters\")\n",
    "    .add(so.Line())\n",
    "    .add(so.Text(), so.Shift(x=0.0, y=0.0025))\n",
    ").theme({\"figure.figsize\": (10, 7)})\n",
    "\n",
    "fig = g.plot()._figure\n",
    "fig.axes[0].set_xticklabels(fig.axes[0].get_xticklabels(), rotation=45)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "\n",
    "g = (\n",
    "    so.Plot(results_df, \"resolution\", \"davies_bouldin_score\", text=\"number_of_clusters\")\n",
    "    .add(so.Line())\n",
    "    .add(so.Text(), so.Shift(x=0.0, y=0.025))\n",
    ").theme({\"figure.figsize\": (10, 7)})\n",
    "\n",
    "fig = g.plot()._figure\n",
    "fig.axes[0].set_xticklabels(fig.axes[0].get_xticklabels(), rotation=45)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing all clustering solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "indcies = select_n_uniform(len(clustering_keys_added), 5)\n",
    "\n",
    "if indcies[-1] != len(clustering_keys_added) - 1:\n",
    "    indcies.append(len(clustering_keys_added) - 1)\n",
    "\n",
    "plot_cols = [clustering_keys_added[i] for i in indcies]\n",
    "with rc_context({\"figure.figsize\": (6, 6)}):\n",
    "    sc.pl.umap(adata, color=adata.obs[plot_cols].columns, ncols=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "# Over-ride the final clustering col\n",
    "CLUSTERING_COL = \"leiden_1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "\n",
    "# TODO: Remove the unsed Clustering col\n",
    "\n",
    "if len(CLUSTERING_COL) > 0 and CLUSTERING_COL not in adata.obs.columns:\n",
    "    raise ValueError(f\"{CLUSTERING_COL} column is not found in the object\")\n",
    "\n",
    "if len(CLUSTERING_COL) > 0 and CLUSTERING_COL in adata.obs.columns:\n",
    "    adata.uns[\"CLUSTERING_COL\"] = CLUSTERING_COL\n",
    "    clustering_keys_added = list(\n",
    "        set(clustering_keys_added).difference(set([CLUSTERING_COL]))\n",
    "    )\n",
    "    # Remove the unused clustering columns, Keep only the final clustering column.\n",
    "    adata.obs.drop(columns=clustering_keys_added, inplace=True)\n",
    "    adata.uns[\"FINAL_CLUSTERED\"] = True\n",
    "else:\n",
    "    adata.uns[\"CLUSTERING_COL\"] = \"\"\n",
    "    adata.uns[\"FINAL_CLUSTERED\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | output: false\n",
    "# | warning: false\n",
    "\n",
    "adata.write_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | echo: false\n",
    "# | warning: false\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
