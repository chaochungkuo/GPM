{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "title: QC of scRNA-seq\n",
    "author: Mohamed Mabrouk\n",
    "last compiled: \"{{ datetime.now().strftime('%Y-%m-%d') }}\"\n",
    "\"toc\": true\n",
    "output:\n",
    "    general:\n",
    "        input: false\n",
    "        output_stdout: false\n",
    "        output_error: false\n",
    "        output: true\n",
    "    html:\n",
    "        code_folding: hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pretty_jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -.-|m { input: false, output: false, input_fold: show}\n",
    "\n",
    "import tomlkit\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc_context\n",
    "import patchworklib as pw\n",
    "import seaborn.objects as so\n",
    "\n",
    "from typing import List, Dict, Callable\n",
    "from anndata import AnnData\n",
    "\n",
    "from IPython.display import display\n",
    "from os import walk, path, mkdir, listdir\n",
    "import session_info\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the following cell, override the default pipeline parameters if needed'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -.-|m { input: false, output: false, input_fold: show}\n",
    "\"in the following cell, override the default pipeline parameters if needed\"\n",
    "\n",
    "#QC Params\n",
    "CONCAT_SAMPLES: bool = True         # Concatenate all samples in one object, default: true\n",
    "NMADS: int = 5                      # Number of median absolute deviations for read and gene counts.    \n",
    "NMADS_MITO: int = 3                 # Number of median absolute deviations for mitochondrial genes percentage.\n",
    "CORRECT_AMBIENT_RNA: bool = False   # Correct ambient RNA, uses DecontX, Currently causes multiple erros.\n",
    "FILTER_DOUBLETS: bool = True        # Filter doublets using Scrublet\n",
    "CELL_CYCLE_SCORE: bool = True       # Calculate cell cycle scores, based on scanpy implementation.\n",
    "REGRESS: bool = False               # Regress out unwanted variables. Not recommended.\n",
    "VARS_TO_REGRESS: List[str] = []     # list of regress (pct_counts_mt, pct_counts_ribo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "## Utility Functions\n",
    "def get_sample_name(file_path: str, black_list: list[str], n = 3):\n",
    "    \"\"\"\"Function to return probable sample name from a path, it recurselvy goes through the path and returns the first element not in the black list.\"\"\"\n",
    "    if n == 0:\n",
    "        return \"\"\n",
    "\n",
    "    tmp = path.basename(file_path)\n",
    "    _d = path.dirname(file_path)\n",
    "\n",
    "    if all(entry not in tmp for entry in black_list):\n",
    "        return tmp\n",
    "    else:\n",
    "        res = get_sample_name(_d, black_list, n-1)\n",
    "    return res\n",
    "\n",
    "\n",
    "def is_outlier(adata: AnnData, metric: str, nmads: int):\n",
    "    \n",
    "    M = adata.obs[metric]\n",
    "    outlier = (M < np.median(M) - nmads * median_abs_deviation(M)) | (\n",
    "        np.median(M) + nmads * median_abs_deviation(M) < M\n",
    "    )\n",
    "    return outlier\n",
    "\n",
    "\n",
    "def read_parsebio(data_path: str):\n",
    "    \"\"\"Reads ParseBio\n",
    "\n",
    "    Args:\n",
    "        data_path (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "\n",
    "    adata = sc.read_mtx(data_path + 'count_matrix.mtx')\n",
    "\n",
    "    # reading in gene and cell data\n",
    "    gene_data = pd.read_csv(data_path + 'all_genes.csv')\n",
    "    cell_meta = pd.read_csv(data_path + 'cell_metadata.csv')\n",
    "\n",
    "    # find genes with nan values and filter\n",
    "    gene_data = gene_data[gene_data.gene_name.notnull()]\n",
    "    notNa = gene_data.index\n",
    "    notNa = notNa.to_list()\n",
    "\n",
    "    # remove genes with nan values and assign gene names\n",
    "    adata = adata[:,notNa]\n",
    "    adata.var = gene_data\n",
    "    adata.var.set_index('gene_name', inplace=True)\n",
    "    adata.var.index.name = None\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    # add cell meta data to anndata object\n",
    "    adata.obs = cell_meta\n",
    "    adata.obs.set_index('bc_wells', inplace=True)\n",
    "    adata.obs.index.name = None\n",
    "    adata.obs_names_make_unique()\n",
    "\n",
    "    return adata\n",
    "\n",
    "\n",
    "\n",
    "def human2mouse(genes: List[str]) -> List[str]:\n",
    "\n",
    "    r = requests.post(\n",
    "        url='https://biit.cs.ut.ee/gprofiler/api/orth/orth/',\n",
    "        json={\n",
    "            'organism':'hsapiens',\n",
    "            'target':'mmusculus',\n",
    "            'query':genes,\n",
    "        }\n",
    "        )\n",
    "    df = pd.DataFrame(r.json()['result'], )\n",
    "    return df.name.replace(\"N/A\", pd.NA).dropna().to_list()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Technology components\n",
    "\n",
    "inputs: Dict[str, List|Callable] = {\n",
    "          \"10x\":{\n",
    "                 \"files\": ['features.tsv.gz', 'barcodes.tsv.gz', 'matrix.mtx.gz'],\n",
    "                 \"black_list\": [\"filtered_feature_bc\", \"raw_feature_bc\", \"count\", \"outs\"],\n",
    "                 \"raw_name\": \"raw_feature_bc_matrix\",\n",
    "                 \"function\": sc.read_10x_mtx\n",
    "                 },\n",
    "\n",
    "          \"ParseBio\":{\n",
    "                    \"files\": [\"all_genes.csv\", \"cell_metadata.csv\", \"count_matrix.mtx\"],\n",
    "                    \"black_list\": [\"DGE_filtered\", \"DGE_unfiltered\"],\n",
    "                    \"function\": read_parsebio\n",
    "                    }\n",
    "          }\n",
    "\n",
    "\n",
    "qc_features_fac: Dict[str, List[str]] = {\"human\": {\n",
    "                         \"mito\": [\"MT-\"],\n",
    "                         \"ribo\": [\"RBS\", \"RPL\"],\n",
    "                         \"hb\": [\"^HB[^(P)]\"]\n",
    "                         },\n",
    "               \"mouse\": {\n",
    "                        \"mito\": [\"mt\"],\n",
    "                        \"ribo\": [\"Rps\", \"Rpl\"],\n",
    "                        \"hb\": [\"^Hb[^(p)]\"] # Validate this later\n",
    "               }\n",
    "                         }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline parameters\n",
    "\n",
    "with open(\"../config.toml\", \"r\") as f:\n",
    "    config = tomlkit.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories \n",
    "ROOT_DIR = config[\"basic\"][\"ANALYSIS_DIR\"]\n",
    "DIR_SAVE = path.join(ROOT_DIR, config[\"basic\"][\"DIR_SAVE\"])\n",
    "DIR_samples = config[\"basic\"][\"DIR_SAMPLES\"]\n",
    "\n",
    "#Basic information\n",
    "TECHNOLOGY: str = config[\"basic\"][\"TECHNOLOGY\"]\n",
    "ORGANISM: str = config[\"basic\"][\"ORGANISM\"]\n",
    "AUTODISCOVER: bool = config[\"basic\"][\"auto_find\"]\n",
    "samples: Dict[str, str] = config[\"basic\"][\"samples\"]\n",
    "\n",
    "sample_components = inputs[TECHNOLOGY][\"files\"]\n",
    "black_list = inputs[TECHNOLOGY][\"black_list\"]\n",
    "read_function = inputs[TECHNOLOGY][\"function\"]\n",
    "raw_name = inputs[TECHNOLOGY][\"raw_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosic pipeline\n",
    "## Reading files\n",
    "\n",
    "if AUTODISCOVER and len(samples) == 0:\n",
    "    files = walk(DIR_samples)\n",
    "    for root, dir, files in files:\n",
    "        if len(set(sample_components).difference(set(files))) == 0 and path.basename(root) != raw_name:\n",
    "            samples[get_sample_name(root, black_list, 5)] = root\n",
    "else:\n",
    "    samples = config[\"basic\"][\"samples\"]\n",
    "    if len(samples) > 0:\n",
    "        pass\n",
    "    else:\n",
    "        raise RuntimeError(\"No samples paths were provided, provide sample paths as a dictionary in 'config.toml'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples (auto-discovered or manually added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample4</th>\n",
       "      <td>../test/sample4/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample4/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample4/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample4/filtered_feature_bc_matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample3</th>\n",
       "      <td>../test/sample3/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample3/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample3/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample3/filtered_feature_bc_matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample2</th>\n",
       "      <td>../test/sample2/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample2/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample2/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample2/filtered_feature_bc_matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample1</th>\n",
       "      <td>../test/sample1/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample1/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample1/filtered_feature_bc_matrix</td>\n",
       "      <td>../test/sample1/filtered_feature_bc_matrix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0  \\\n",
       "sample4  ../test/sample4/filtered_feature_bc_matrix   \n",
       "sample3  ../test/sample3/filtered_feature_bc_matrix   \n",
       "sample2  ../test/sample2/filtered_feature_bc_matrix   \n",
       "sample1  ../test/sample1/filtered_feature_bc_matrix   \n",
       "\n",
       "                                                  1  \\\n",
       "sample4  ../test/sample4/filtered_feature_bc_matrix   \n",
       "sample3  ../test/sample3/filtered_feature_bc_matrix   \n",
       "sample2  ../test/sample2/filtered_feature_bc_matrix   \n",
       "sample1  ../test/sample1/filtered_feature_bc_matrix   \n",
       "\n",
       "                                                  2  \\\n",
       "sample4  ../test/sample4/filtered_feature_bc_matrix   \n",
       "sample3  ../test/sample3/filtered_feature_bc_matrix   \n",
       "sample2  ../test/sample2/filtered_feature_bc_matrix   \n",
       "sample1  ../test/sample1/filtered_feature_bc_matrix   \n",
       "\n",
       "                                                  3  \n",
       "sample4  ../test/sample4/filtered_feature_bc_matrix  \n",
       "sample3  ../test/sample3/filtered_feature_bc_matrix  \n",
       "sample2  ../test/sample2/filtered_feature_bc_matrix  \n",
       "sample1  ../test/sample1/filtered_feature_bc_matrix  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(samples, index = list(range(len(samples)))).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No/Multiple raw files meeting condition were found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     adata_raw \u001b[38;5;241m=\u001b[39m sc\u001b[38;5;241m.\u001b[39mread_10x_h5(path\u001b[38;5;241m.\u001b[39mjoin(path\u001b[38;5;241m.\u001b[39mdirname(filename), raw_file[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo/Multiple raw files meeting condition were found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m adata_raw\u001b[38;5;241m.\u001b[39mvar_names_make_unique()\n\u001b[1;32m     19\u001b[0m raw_h5[sample_id] \u001b[38;5;241m=\u001b[39m adata_raw\n",
      "\u001b[0;31mValueError\u001b[0m: No/Multiple raw files meeting condition were found"
     ]
    }
   ],
   "source": [
    "adatas = {}\n",
    "raw_h5 = {}\n",
    "for sample_id, filename in samples.items():\n",
    "    sample_adata = read_function(filename)\n",
    "    sample_adata.var_names_make_unique()\n",
    "    adatas[sample_id] = sample_adata\n",
    "\n",
    "\n",
    "#TODO: Improve the unfiltered matrix detection heuristic\n",
    "if TECHNOLOGY == \"10x\" and CORRECT_AMBIENT_RNA:\n",
    "    for sample_id, filename in samples.items():\n",
    "        files = listdir(path.dirname(filename))\n",
    "        raw_file = [file for file in files if \"raw_feature_bc_matrix\" in file and \".h5\" in file]\n",
    "        if len(raw_file) == 1:\n",
    "            adata_raw = sc.read_10x_h5(path.join(path.dirname(filename), raw_file[0]))\n",
    "        else:\n",
    "            raise ValueError(\"No/Multiple raw files meeting condition were found\")\n",
    "\n",
    "        adata_raw.var_names_make_unique()\n",
    "        raw_h5[sample_id] = adata_raw\n",
    "\n",
    "\n",
    "if CONCAT_SAMPLES:\n",
    "    adata = ad.concat(adatas, label=\"sample\", join=\"outer\", merge=\"same\")\n",
    "    adata.obs_names_make_unique()\n",
    "    del samples\n",
    "\n",
    "if CONCAT_SAMPLES and TECHNOLOGY == \"10x\" and CORRECT_AMBIENT_RNA:\n",
    "    adata_raw = ad.concat(raw_h5, label=\"sample\", join=\"outer\", merge=\"same\")\n",
    "    adata_raw.obs_names_make_unique()\n",
    "    del raw_h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding quality metrics\n",
    "\n",
    "\n",
    "\"\"\"**TODO:**\n",
    "- [ ] Handle also multple samples at once\n",
    "- [ ] Make the Oulier function parameterized on sample\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "mt_features = qc_features_fac[ORGANISM][\"mito\"]\n",
    "rb_features = qc_features_fac[ORGANISM][\"ribo\"]\n",
    "hb_features = qc_features_fac[ORGANISM][\"hb\"]\n",
    "\n",
    "\n",
    "# mitochondrial genes, \"MT-\" for human, \"Mt-\" for mouse\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(tuple(mt_features))\n",
    "# ribosomal genes\n",
    "adata.var[\"ribo\"] = adata.var_names.str.startswith(tuple(rb_features))\n",
    "# hemoglobin genes\n",
    "adata.var[\"hb\"] = adata.var_names.str.contains(tuple(hb_features)[0]) #Only regex is accepted\n",
    "\n",
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=[\"mt\", \"ribo\", \"hb\"], percent_top=[20],  inplace=True, log1p=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add additional Critera for filtering based on Absolute thresholds, can it be per sample?\n",
    "\n",
    "adata.obs[\"outlier\"] = (\n",
    "    is_outlier(adata, \"log1p_total_counts\", NMADS)\n",
    "    | is_outlier(adata, \"log1p_n_genes_by_counts\", NMADS)\n",
    "    #| is_outlier(adata, \"pct_counts_in_top_20_genes\", NMADS)\n",
    ")\n",
    "\n",
    "adata.obs[\"mt_outlier\"] = is_outlier(adata, \"pct_counts_mt\", NMADS_MITO) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ambient RNA correction\n",
    "## TODO: Check if the Ambient RNA can be improved by using Batch information?\n",
    "\n",
    "if CORRECT_AMBIENT_RNA and TECHNOLOGY == \"10x\":\n",
    "\n",
    "    from os import system, remove, path\n",
    "    import tempfile\n",
    "\n",
    "    with tempfile.TemporaryDirectory(dir=\".\") as tmpdirname:\n",
    "        # Define paths for temporary files\n",
    "        sce_path = path.join(tmpdirname, \"sce.h5ad\")\n",
    "        raw_path = path.join(tmpdirname, \"raw.h5ad\")\n",
    "        decontx_path = path.join(tmpdirname, \"decontX.h5ad\")\n",
    "        \n",
    "        # Save adata and adata_raw to the temporary directory\n",
    "        adata.write_h5ad(sce_path)\n",
    "        adata_raw.write_h5ad(raw_path)\n",
    "        \n",
    "        # Execute R scripts with temporary file paths\n",
    "        system(f\"Rscript ./utils/deconx.R -s {sce_path} -r {raw_path} -o {decontx_path}\")\n",
    "\n",
    "        # Read the result back from the temporary directory\n",
    "        adata = sc.read_h5ad(decontx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doublet Detection\n",
    "\n",
    "#TODO: Check real-life performance\n",
    "#TODO: Check Interop with R to convert object to R & vice-versa \n",
    "if FILTER_DOUBLETS:\n",
    "    sc.pp.scrublet(adata, batch_key=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell cycle Scoring\n",
    "# **Not reliable, do via interop later**\n",
    "\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.scale(adata)\n",
    "\n",
    "\n",
    "if CELL_CYCLE_SCORE:\n",
    "    if ORGANISM in [\"human\", \"mouse\"]:\n",
    "\n",
    "        s_genes = [x.strip() for x in open('../resources/s_genes.txt')]\n",
    "        g2m_genes = [x.strip() for x in open('../resources/s_genes.txt')]\n",
    "\n",
    "\n",
    "        if ORGANISM == \"mouse\":\n",
    "            s_genes = human2mouse(s_genes)\n",
    "            g2m_genes = human2mouse(g2m_genes)\n",
    "\n",
    "\n",
    "        # Cell cycle scoring is not reliable and not similair to Seurat\n",
    "        sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)\n",
    "    else:\n",
    "        logging.error('Organism must be either human or mouse.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.set_figure_params(dpi=300, color_map=\"viridis_r\")\n",
    "# sc.settings.verbosity = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic QC plots & metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\", \"pct_counts_ribo\"]\n",
    "\n",
    "if FILTER_DOUBLETS:\n",
    "    keys = keys + [\"doublet_score\"]\n",
    "\n",
    "if CELL_CYCLE_SCORE:\n",
    "    keys = keys + [\"S_score\", \"G2M_score\"]\n",
    "\n",
    "ncols = 2\n",
    "nrows = len(keys) // ncols + len(keys) % ncols\n",
    "\n",
    "\n",
    "figsize = 4\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(ncols * figsize + figsize * wspace * (ncols - 1), nrows * figsize),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace)\n",
    "# Prevent the subplots from showing \n",
    "plt.close(fig)\n",
    "\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    row = i // ncols\n",
    "    col = i % ncols\n",
    "    sc.pl.violin(adata, keys=[key], groupby=\"sample\", stripplot=False, inner=\"box\", ax=axs[row, col])\n",
    "\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of basic QC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = adata.obs.groupby(\"sample\")[keys].agg([\"mean\", \"median\"]).round(3)\n",
    "df2 = adata.obs.groupby(\"sample\")[[\"sample\"]].agg([\"size\"])\n",
    "pd.concat([df1, df2], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df = adata.obs[keys]\n",
    "\n",
    "# Determine the number of rows and columns for your subplot grid\n",
    "n = len(df.columns)\n",
    "ncols = 2\n",
    "nrows = n // ncols + (n % ncols > 0)\n",
    "\n",
    "# Create the subplots\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(ncols * figsize + figsize * wspace * (ncols - 1), nrows * figsize + wspace * (nrows - 1) ),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "\n",
    "# Flatten the axes\n",
    "axs = axs.flatten()\n",
    "\n",
    "outlier_dict = {}\n",
    "\n",
    "\n",
    "# Plot a histogram on each subplot\n",
    "for i, col in enumerate(df.columns):\n",
    "    sns.histplot(data=df, x=col, ax=axs[i], bins=300)\n",
    "\n",
    "    if col in [\"n_genes_by_counts\", \"total_counts\"]:\n",
    "        max_line = min(df[col].agg(\"mean\")+ median_abs_deviation(df[col]) * NMADS,  df[col].agg(\"max\")) \n",
    "        min_line = max(df[col].agg(\"mean\") - median_abs_deviation(df[col]) * NMADS, df[col].agg(\"min\"))\n",
    "        axs[i].axvline(x=max_line, color='red', linestyle='--', linewidth = 0.7)\n",
    "        axs[i].axvline(x=min_line, color='red', linestyle='--', linewidth = 0.7)\n",
    "\n",
    "        outlier_dict[col] = (min_line, max_line)\n",
    "\n",
    "    if col is \"pct_counts_mt\":\n",
    "        max_line = min(df[col].agg(\"mean\")+ median_abs_deviation(df[col]) * NMADS_MITO,  df[col].agg(\"max\")) \n",
    "        min_line = max(df[col].agg(\"mean\") - median_abs_deviation(df[col]) * NMADS_MITO, df[col].agg(\"min\"))\n",
    "        axs[i].axvline(x=max_line, color='red', linestyle='--', linewidth = 0.7)\n",
    "        axs[i].axvline(x=min_line, color='red', linestyle='--', linewidth = 0.7)\n",
    "\n",
    "        outlier_dict[col] = (min_line, max_line)\n",
    "\n",
    "# Remove any unused subplots\n",
    "if len(df.columns) < nrows*ncols:\n",
    "    for i in range(len(df.columns), nrows*ncols):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_filters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(outlier_dict, index= (\"Min\", \"Max\")).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of outliers based on provided criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(adata.obs[[\"outlier\", \"mt_outlier\", \"sample\"]].value_counts(subset=[\"outlier\",  \"sample\"]))\n",
    "df2 = pd.DataFrame(adata.obs[[\"outlier\", \"mt_outlier\", \"sample\"]].value_counts(subset=[\"mt_outlier\",  \"sample\"]))\n",
    "\n",
    "df1.columns = [\"Outlier\"]\n",
    "df2.columns = [\"MT-Outlier\"]\n",
    "\n",
    "pd.concat([df1,df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell filtering based on outlier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving The object at the last step before subsseting\n",
    "if path.exists(DIR_SAVE):\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"raw_adata.h5ad\"))\n",
    "else:\n",
    "    mkdir(DIR_SAVE)\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"raw_adata.h5ad\"))\n",
    "\n",
    "\n",
    "# Cell Filtering based on threshold\n",
    "adata = adata[(~adata.obs.outlier) & (~adata.obs.mt_outlier)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = adata.obs.groupby(\"sample\")[keys].agg([\"mean\", \"median\"]).round(3)\n",
    "df2 = adata.obs.groupby(\"sample\")[[\"sample\"]].agg([\"size\"])\n",
    "pd.concat([df1, df2], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots of confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df = adata.obs[keys+[\"sample\"]]\n",
    "\n",
    "# Determine the number of rows and columns for your subplot grid\n",
    "n = len(df.columns)\n",
    "ncols = 2\n",
    "nrows = 2\n",
    "figsize= 4\n",
    "\n",
    "# Create the subplots\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(ncols * figsize + figsize * wspace * (ncols - 1), nrows * figsize + wspace * (nrows - 1) ),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "\n",
    "# Flatten the axes\n",
    "axs = axs.flatten()\n",
    "\n",
    "sns.scatterplot(df, x=\"total_counts\", y=\"n_genes_by_counts\", hue = \"sample\", alpha = 0.4, s = 6,  ax= axs[0])\n",
    "sns.scatterplot(df, x=\"total_counts\", y=\"pct_counts_mt\", hue = \"sample\", alpha = 0.4, s = 6,  ax= axs[1])\n",
    "sns.scatterplot(df, x=\"total_counts\", y=\"pct_counts_ribo\", hue = \"sample\", alpha = 0.4, s = 6,  ax= axs[2])\n",
    "\n",
    "if FILTER_DOUBLETS:\n",
    "    sns.scatterplot(df, x=\"total_counts\", y=\"doublet_score\", hue = \"sample\", alpha = 0.4, s = 6,  ax= axs[3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecontX contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if CORRECT_AMBIENT_RNA and TECHNOLOGY == \"10x\":\n",
    "    ax1 = pw.Brick(figsize=(6,6))\n",
    "    ax2 = pw.Brick(figsize=(6,6))\n",
    "\n",
    "    scatter = sns.scatterplot(pd.concat([adata.obsm[\"decontX_UMAP\"], adata.obs], axis = 1), x = \"DecontX_UMAP_1\", y = \"DecontX_UMAP_2\", hue= \"decontX_contamination\" , s= 0.8, ax = ax1, palette=\"inferno\")\n",
    "    sns.move_legend(scatter, \"center right\", bbox_to_anchor=(1.1, 0.5), title=None, frameon=False)\n",
    "\n",
    "    scatter = sns.scatterplot(pd.concat([adata.obsm[\"decontX_UMAP\"], adata.obs], axis = 1), x = \"DecontX_UMAP_1\", y = \"DecontX_UMAP_2\", hue= \"decontX_clusters\" , s= 0.8, ax=ax2)\n",
    "    sns.move_legend(scatter, \"center right\", bbox_to_anchor=(1.15, 0.5), title=None, frameon=False)\n",
    "\n",
    "    ax12 = ax1+ax2\n",
    "    display(ax12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering after to cell filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata, n_comps=20)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.leiden(adata, key_added=\"groups\", flavor=\"igraph\")\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -.-|m { input: false, output: true, input_fold: show}\n",
    "keys = [\"sample\", \"total_counts\", \"n_genes_by_counts\", \"pct_counts_mt\"]\n",
    "\n",
    "if FILTER_DOUBLETS:\n",
    "    keys = keys + [\"predicted_doublet\"]\n",
    "\n",
    "if CELL_CYCLE_SCORE:\n",
    "    keys = keys + [\"phase\"]\n",
    "\n",
    "figs = sc.pl.umap(adata, size= 7, color= keys, show=False, ncols = 2, color_map=\"inferno\", sort_order=False, alpha = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - [ ] Add error handling if the vars to regress is empty or contain non-keys\n",
    "if REGRESS:\n",
    "    sc.pp.regress_out(adata, keys= VARS_TO_REGRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambient RNA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORRECT_AMBIENT_RNA:\n",
    "    sns.violinplot(adata.obs, x = \"decontX_clusters\", y = \"decontX_contamination\")\n",
    "    sns.stripplot(adata.obs, x = \"decontX_clusters\", y = \"decontX_contamination\", s = 1, c = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Result\n",
    "if path.exists(DIR_SAVE):\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))\n",
    "else:\n",
    "    mkdir(DIR_SAVE)\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
