{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "title: QC of scRNA-seq\n",
    "author: Mohamed Mabrouk\n",
    "last compiled: \"{{ datetime.now().strftime('%Y-%m-%d') }}\"\n",
    "output:\n",
    "    general:\n",
    "        input: false\n",
    "        output_stdout: false\n",
    "        output_error: false\n",
    "        output: true\n",
    "    html:\n",
    "        toc: true\n",
    "        tabset: false\n",
    "        code_folding: hide\n",
    "        code_tools: true\n",
    "        number_sections: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pretty_jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 100x100 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -.-|m { input: false, output: false, input_fold: show}\n",
    "\n",
    "import tomlkit\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc_context\n",
    "import patchworklib as pw\n",
    "import seaborn.objects as so\n",
    "\n",
    "from typing import List, Dict\n",
    "\n",
    "from IPython.display import display\n",
    "from os import walk, path, mkdir, listdir, cpu_count\n",
    "import session_info\n",
    "import logging\n",
    "from utils.preprocessing_funcs import *\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "sc.set_figure_params(dpi = 100, dpi_save = 300, format= \"png\")\n",
    "sc.settings.n_jobs = int(cpu_count() * 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -.-|m { input: false, output: false, input_fold: show}\n",
    "\"in the following cell, override the default pipeline parameters if needed\"\n",
    "\n",
    "#QC Params\n",
    "CONCAT_SAMPLES: bool = True         # Concatenate all samples in one object, default: true\n",
    "NMADS: int = 5                      # Number of median absolute deviations for read and gene counts.    \n",
    "NMADS_MITO: int = 3                 # Number of median absolute deviations for mitochondrial genes percentage.\n",
    "CORRECT_AMBIENT_RNA: bool = False   # Correct ambient RNA, uses DecontX, Currently causes multiple erros.\n",
    "FILTER_DOUBLETS: bool = False        # Filter doublets using Scrublet\n",
    "CELL_CYCLE_SCORE: bool = True       # Calculate cell cycle scores, based on scanpy implementation.\n",
    "REGRESS: bool = False               # Regress out unwanted variables. Not recommended.\n",
    "VARS_TO_REGRESS: List[str] = []     # list of regress (pct_counts_mt, pct_counts_ribo).\n",
    "\n",
    "\n",
    "\n",
    "# QC Dict\n",
    "\"\"\"\n",
    "Can either be a flat-dict for global threshold or a dict of dicts for each sample \n",
    "Entries are in the form of col_name: [low, high] Ex: 'mt_pct':[0, 20]\n",
    "\"\"\"\n",
    "\n",
    "qc_dict = {}\n",
    "\n",
    "# MODIFY_ME, Specifiy only after running diagnotics on the samples\n",
    "# global config\n",
    "qc_dict: Dict[str, List] | Dict[str, List] = {\n",
    "    \"pct_counts_mt\": [0, 10],\n",
    "    \"pct_counts_rb\": [0, 10],\n",
    "    \"n_genes_by_counts\": [1500, 9000],\n",
    "    \"total_counts\": [3_000, 40_000]\n",
    "}\n",
    "\n",
    "\n",
    "# # per-sample config\n",
    "# qc_dict: Dict[str, List] | Dict[str, List] = {\n",
    "#     \"sample1\": {\n",
    "#         \"pct_counts_mt\": [0, 10],\n",
    "#         \"pct_counts_rb\": [0, 10],\n",
    "#         \"n_genes_by_counts\": [1500, 9000],\n",
    "#         \"total_counts\": [3_000, 40_000]\n",
    "#     },\n",
    "#     \"sample2\": {\n",
    "#         \"pct_counts_mt\": [0, 10],\n",
    "#         \"pct_counts_rb\": [0, 10],\n",
    "#         \"n_genes_by_counts\": [1500, 9000],\n",
    "#         \"total_counts\": [3_000, 40_000]\n",
    "#     },\n",
    "#     \"sample3\": {\n",
    "#         \"pct_counts_mt\": [0, 10],\n",
    "#         \"pct_counts_rb\": [0, 10],\n",
    "#         \"n_genes_by_counts\": [1500, 9000],\n",
    "#         \"total_counts\": [3_000, 40_000]\n",
    "#     },\n",
    "#     \"sample4\": {\n",
    "#         \"pct_counts_mt\": [0, 10],\n",
    "#         \"pct_counts_rb\": [0, 10],\n",
    "#         \"n_genes_by_counts\": [1500, 9000],\n",
    "#         \"total_counts\": [3_000, 40_000]\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline parameters\n",
    "\n",
    "with open(\"../config.toml\", \"r\") as f:\n",
    "    config = tomlkit.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directories \n",
    "ROOT_DIR = config[\"basic\"][\"ANALYSIS_DIR\"]\n",
    "DIR_SAVE = path.join(ROOT_DIR, config[\"basic\"][\"DIR_SAVE\"])\n",
    "DIR_samples = config[\"basic\"][\"DIR_SAMPLES\"]\n",
    "\n",
    "#Basic information\n",
    "TECHNOLOGY: str = config[\"basic\"][\"TECHNOLOGY\"]\n",
    "ORGANISM: str = config[\"basic\"][\"ORGANISM\"]\n",
    "AUTODISCOVER: bool = config[\"basic\"][\"auto_find\"]\n",
    "samples: Dict[str, str] = config[\"basic\"][\"samples\"]\n",
    "\n",
    "sample_components = inputs[TECHNOLOGY][\"files\"]\n",
    "black_list = inputs[TECHNOLOGY][\"black_list\"]\n",
    "read_function = inputs[TECHNOLOGY][\"function\"]\n",
    "raw_name = inputs[TECHNOLOGY][\"raw_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosic pipeline\n",
    "## Reading files\n",
    "\n",
    "if AUTODISCOVER and len(samples) == 0:\n",
    "    files = walk(DIR_samples)\n",
    "    for root, dir, files in files:\n",
    "        if len(set(sample_components).difference(set(files))) == 0 and path.basename(root) != raw_name:\n",
    "            samples[get_sample_name(root, black_list, 5)] = root\n",
    "else:\n",
    "    samples = config[\"basic\"][\"samples\"]\n",
    "    if len(samples) > 0:\n",
    "        pass\n",
    "    else:\n",
    "        raise RuntimeError(\"No samples paths were provided, provide sample paths as a dictionary in 'config.toml'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samples (auto-discovered or manually added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sample4</th>\n",
       "      <td>../test/sample4/filtered_feature_bc_matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample3</th>\n",
       "      <td>../test/sample3/filtered_feature_bc_matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample2</th>\n",
       "      <td>../test/sample2/filtered_feature_bc_matrix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample1</th>\n",
       "      <td>../test/sample1/filtered_feature_bc_matrix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sample path\n",
       "sample4  ../test/sample4/filtered_feature_bc_matrix\n",
       "sample3  ../test/sample3/filtered_feature_bc_matrix\n",
       "sample2  ../test/sample2/filtered_feature_bc_matrix\n",
       "sample1  ../test/sample1/filtered_feature_bc_matrix"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(samples,  index = [\"sample path\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adatas = {}\n",
    "raw_h5 = {}\n",
    "for sample_id, filename in samples.items():\n",
    "    sample_adata = read_function(filename)\n",
    "    sample_adata.var_names_make_unique()\n",
    "    adatas[sample_id] = sample_adata\n",
    "\n",
    "\n",
    "if TECHNOLOGY == \"10x\" and CORRECT_AMBIENT_RNA:\n",
    "    for sample_id, filename in samples.items():\n",
    "        files = listdir(path.dirname(filename))\n",
    "        raw_file = [file for file in files if \"raw_feature_bc_matrix\" in file and \".h5\" in file]\n",
    "        if len(raw_file) == 1:\n",
    "            adata_raw = sc.read_10x_h5(path.join(path.dirname(filename), raw_file[0]))\n",
    "        else:\n",
    "            raise ValueError(\"No/Multiple raw files meeting condition were found\")\n",
    "\n",
    "        adata_raw.var_names_make_unique()\n",
    "        raw_h5[sample_id] = adata_raw\n",
    "\n",
    "\n",
    "if CONCAT_SAMPLES:\n",
    "    adata = ad.concat(adatas, label=\"sample\", join=\"outer\", merge=\"same\")\n",
    "    adata.obs_names_make_unique()\n",
    "    del samples\n",
    "\n",
    "if CONCAT_SAMPLES and TECHNOLOGY == \"10x\" and CORRECT_AMBIENT_RNA:\n",
    "    adata_raw = ad.concat(raw_h5, label=\"sample\", join=\"outer\", merge=\"same\")\n",
    "    adata_raw.obs_names_make_unique()\n",
    "    del raw_h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding quality metrics\n",
    "\n",
    "\n",
    "\"\"\"**TODO:**\n",
    "- [ ] Make the Oulier function parameterized on sample\n",
    "\"\"\"\n",
    "\n",
    "mt_features = qc_features_fac[ORGANISM][\"mito\"]\n",
    "rb_features = qc_features_fac[ORGANISM][\"ribo\"]\n",
    "hb_features = qc_features_fac[ORGANISM][\"hb\"]\n",
    "\n",
    "\n",
    "# mitochondrial genes, \"MT-\" for human, \"Mt-\" for mouse\n",
    "adata.var[\"mt\"] = adata.var_names.str.startswith(tuple(mt_features))\n",
    "# ribosomal genes\n",
    "adata.var[\"rb\"] = adata.var_names.str.startswith(tuple(rb_features))\n",
    "# hemoglobin genes\n",
    "adata.var[\"hb\"] = adata.var_names.str.contains(tuple(hb_features)[0]) #Only regex is accepted\n",
    "\n",
    "sc.pp.calculate_qc_metrics(\n",
    "    adata, qc_vars=[\"mt\", \"rb\", \"hb\"], percent_top=[20],  inplace=True, log1p=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Add additional Critera for filtering based on Absolute thresholds, can it be per sample?\n",
    "if len(qc_dict) > 0 and all(map(lambda x: isinstance(x, list), qc_dict.values())):\n",
    "    reduce_outliers(adata, qc_dict)\n",
    "elif len(qc_dict) > 0 and all(map(lambda x: isinstance(x, dict), qc_dict.values())):\n",
    "    for sample in qc_dict.keys():\n",
    "        reduce_outliers(adata, qc_dict[sample], sample)\n",
    "else:\n",
    "    adata.obs[\"total_counts_outlier\"] = is_outlier(adata, \"total_counts\", NMADS)\n",
    "    adata.obs[\"n_genes_by_counts_outlier\"] = is_outlier(adata, \"n_genes_by_counts\", NMADS)\n",
    "    adata.obs[\"pct_counts_mt_outlier\"] = is_outlier(adata, \"pct_counts_mt\", NMADS_MITO)\n",
    "    adata.obs[\"outlier\"] = adata.obs[\"total_counts_outlier\"] | adata.obs[\"n_genes_by_counts_outlier\"] | adata.obs[\"pct_counts_mt_outlier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reduce_outliers(adata: AnnData, variables: Dict[str, List], subset: str|None = None) -> pd.Series:\n",
    "    outlier_dict = {}\n",
    "\n",
    "    if subset is not None:\n",
    "        for key in variables.keys():\n",
    "            if key in adata.obs.columns:\n",
    "                if len(variables[key]) == 2:\n",
    "                    try:\n",
    "                        adata.obs.loc[adata.obs[\"sample\"] == subset, f\"{key}_outlier\"] = adata.obs.loc[adata.obs[\"sample\"] == subset, key].lt(variables[key][0]) | \\\n",
    "                              adata.obs.loc[adata.obs[\"sample\"] == subset, key].gt(variables[key][1])\n",
    "                        outlier_dict[key] = adata.obs[f\"{key}_outlier\"] \n",
    "                    except:\n",
    "                        adata.obs.loc[adata.obs[\"sample\"] == subset, f\"{key}_outlier\"] = outlier_dict[key]\n",
    "                        outlier_dict[key] = adata.obs[f\"{key}_outlier\"] \n",
    "                else:\n",
    "                    raise ValueError(\"Provide a list of length 2 for the lower and upper bound of the QC-variable.\")\n",
    "            else:\n",
    "                raise KeyError(\"the provided QC variable does not exist in the data, check the variable names again.\")\n",
    "            \n",
    "        return reduce(lambda x, y: x or y, zip(outlier_dict.values()))\n",
    "\n",
    "    for key in variables.keys():\n",
    "        if key in adata.obs.columns:\n",
    "            if len(variables[key]) == 2:\n",
    "                outlier_dict[key] = adata.obs[key].lt(variables[key][0]) | adata.obs[key].gt(variables[key][1])\n",
    "                adata.obs[f\"{key}_outlier\"] = outlier_dict[key]\n",
    "            else:\n",
    "                raise ValueError(\"Provide a list of length 2 for the lower and upper bound of the QC-variable.\")\n",
    "        else:\n",
    "            raise KeyError(\"the provided QC variable does not exist in the data, check the variable names again.\")\n",
    "\n",
    "    return reduce(lambda x, y: x or y, zip(outlier_dict.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs.loc[adata.obs[\"sample\"] == \"sample4\", \"pct_counts_rb_outlier\"] = True\n",
    "# for sample in qc_dict.keys():\n",
    "#     print(adata.obs[[\"sample\",\"total_counts_outlier\"]].value_counts())\n",
    "#     reduce_outliers(adata, qc_dict[sample], sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAACCCAAGCCTGTCG-1    True\n",
       "AAACCCACACAATGCT-1    True\n",
       "AAACCCAGTTTACTGG-1    True\n",
       "AAACCCATCATGAGGG-1    True\n",
       "AAACCCATCTACACTT-1    True\n",
       "                      ... \n",
       "TTTGTTGCAGGCTTGC-1    True\n",
       "TTTGTTGGTTACCCTC-1    True\n",
       "TTTGTTGGTTCGGCTG-1    True\n",
       "TTTGTTGTCAATCTTC-1    True\n",
       "TTTGTTGTCAGTGGGA-1    True\n",
       "Name: pct_counts_rb_outlier, Length: 7365, dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.loc[adata.obs[\"sample\"] == \"sample4\", \"pct_counts_rb_outlier\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ambient RNA correction\n",
    "## TODO: Check if the Ambient RNA can be improved by using Batch information?\n",
    "\n",
    "if CORRECT_AMBIENT_RNA and TECHNOLOGY == \"10x\":\n",
    "\n",
    "    from os import system, remove, path\n",
    "    import tempfile\n",
    "    import urllib.request\n",
    "\n",
    "    with tempfile.TemporaryDirectory(dir=\".\") as tmpdirname:\n",
    "\n",
    "        # Workaround failure to install GenomeInfoDbData using pixi\n",
    "        dn_path = path.join(tmpdirname, \"GenomeInfoDbData_1.2.11.tar.gz\")\n",
    "        dn_url = \"https://bioconductor.org/packages/3.18/data/annotation/src/contrib/GenomeInfoDbData_1.2.11.tar.gz\"\n",
    "        urllib.request.urlretrieve(dn_url, filename=dn_path)\n",
    "        system(f\"R CMD INSTALL {dn_path}\")\n",
    "\n",
    "        # Define paths for temporary files\n",
    "        sce_path = path.join(tmpdirname, \"sce.h5ad\")\n",
    "        raw_path = path.join(tmpdirname, \"raw.h5ad\")\n",
    "        decontx_path = path.join(tmpdirname, \"decontX.h5ad\")\n",
    "        \n",
    "        # Save adata and adata_raw to the temporary directory\n",
    "        adata.write_h5ad(sce_path)\n",
    "        adata_raw.write_h5ad(raw_path)\n",
    "        \n",
    "        # Execute R scripts with temporary file paths\n",
    "        system(f\"Rscript ./utils/deconx.R -s {sce_path} -r {raw_path} -o {decontx_path}\")\n",
    "\n",
    "        # Read the result back from the temporary directory\n",
    "        adata = sc.read_h5ad(decontx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Doublet Detection\n",
    "\n",
    "#TODO: Check real-life performance\n",
    "#TODO: Check Interop with R to convert object to R & vice-versa \n",
    "if FILTER_DOUBLETS and TECHNOLOGY == \"10x\":\n",
    "    sc.pp.scrublet(adata, batch_key=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cell cycle Scoring\n",
    "# **Not reliable, do via interop later**\n",
    "\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.scale(adata)\n",
    "\n",
    "\n",
    "if CELL_CYCLE_SCORE:\n",
    "    if ORGANISM in [\"human\", \"mouse\"]:\n",
    "\n",
    "        s_genes = [x.strip() for x in open('../resources/s_genes.txt')]\n",
    "        g2m_genes = [x.strip() for x in open('../resources/s_genes.txt')]\n",
    "\n",
    "\n",
    "        if ORGANISM == \"mouse\":\n",
    "            s_genes = human2mouse(s_genes)\n",
    "            g2m_genes = human2mouse(g2m_genes)\n",
    "\n",
    "\n",
    "        # Cell cycle scoring is not reliable and not similair to Seurat\n",
    "        sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes)\n",
    "    else:\n",
    "        logging.error('Organism must be either human or mouse.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.set_figure_params(dpi=300, color_map=\"viridis_r\")\n",
    "# sc.settings.verbosity = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic QC plots & metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"n_genes_by_counts\", \"total_counts\", \"pct_counts_mt\", \"pct_counts_rb\"]\n",
    "\n",
    "if FILTER_DOUBLETS:\n",
    "    keys = keys + [\"doublet_score\"]\n",
    "\n",
    "if CELL_CYCLE_SCORE:\n",
    "    keys = keys + [\"S_score\", \"G2M_score\"]\n",
    "\n",
    "ncols = 2\n",
    "nrows = len(keys) // ncols + len(keys) % ncols\n",
    "\n",
    "\n",
    "figsize = 3\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(ncols * figsize + figsize * wspace * (ncols - 1), nrows * figsize),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace)\n",
    "# Prevent the subplots from showing \n",
    "plt.close(fig)\n",
    "\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "    row = i // ncols\n",
    "    col = i % ncols\n",
    "    sc.pl.violin(adata, keys=[key], groupby=\"sample\", stripplot=False, inner=\"box\", ax=axs[row, col])\n",
    "\n",
    "display(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of basic QC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = adata.obs.groupby(\"sample\")[keys].agg([\"mean\", \"median\"]).round(3)\n",
    "df2 = adata.obs.groupby(\"sample\")[[\"sample\"]].agg([\"size\"])\n",
    "pd.concat([df1, df2], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df = adata.obs[keys]\n",
    "\n",
    "# Determine the number of rows and columns for your subplot grid\n",
    "n = len(df.columns)\n",
    "ncols = 2\n",
    "nrows = n // ncols + (n % ncols > 0)\n",
    "\n",
    "# Create the subplots\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(ncols * figsize + figsize * wspace * (ncols - 1), nrows * figsize + wspace * (nrows - 1) ),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "\n",
    "# Flatten the axes\n",
    "axs = axs.flatten()\n",
    "\n",
    "outlier_dict = {}\n",
    "\n",
    "\n",
    "# Plot a histogram on each subplot\n",
    "for i, col in enumerate(df.columns):\n",
    "    sns.histplot(data=df, x=col, ax=axs[i], bins=300)\n",
    "\n",
    "    if col in [\"n_genes_by_counts\", \"total_counts\"]:\n",
    "        max_line = min(df[col].agg(\"mean\")+ median_abs_deviation(df[col]) * NMADS,  df[col].agg(\"max\")) \n",
    "        min_line = max(df[col].agg(\"mean\") - median_abs_deviation(df[col]) * NMADS, df[col].agg(\"min\"))\n",
    "        axs[i].axvline(x=max_line, color='red', linestyle='--', linewidth = 0.7)\n",
    "        axs[i].axvline(x=min_line, color='red', linestyle='--', linewidth = 0.7)\n",
    "\n",
    "        outlier_dict[col] = (min_line, max_line)\n",
    "\n",
    "    elif col in [\"pct_counts_mt\"]:\n",
    "        max_line = min(df[col].agg(\"mean\")+ median_abs_deviation(df[col]) * NMADS_MITO,  df[col].agg(\"max\")) \n",
    "        min_line = max(df[col].agg(\"mean\") - median_abs_deviation(df[col]) * NMADS_MITO, df[col].agg(\"min\"))\n",
    "        axs[i].axvline(x=max_line, color='red', linestyle='--', linewidth = 0.7)\n",
    "        axs[i].axvline(x=min_line, color='red', linestyle='--', linewidth = 0.7)\n",
    "\n",
    "        outlier_dict[col] = (min_line, max_line)\n",
    "\n",
    "# Remove any unused subplots\n",
    "if len(df.columns) < nrows*ncols:\n",
    "    for i in range(len(df.columns), nrows*ncols):\n",
    "        fig.delaxes(axs[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outlier_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43moutlier_dict\u001b[49m, index\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outlier_dict' is not defined"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(outlier_dict, index= (\"Min\", \"Max\")).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of outliers based on provided criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_counts_outlier</th>\n",
       "      <th>n_genes_by_counts_outlier</th>\n",
       "      <th>pct_counts_mt_outlier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <th>sample4</th>\n",
       "      <td>5761</td>\n",
       "      <td>6393</td>\n",
       "      <td>7149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th>sample4</th>\n",
       "      <td>1604</td>\n",
       "      <td>972</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               total_counts_outlier  n_genes_by_counts_outlier  \\\n",
       "      sample                                                     \n",
       "False sample4                  5761                       6393   \n",
       "True  sample4                  1604                        972   \n",
       "\n",
       "               pct_counts_mt_outlier  \n",
       "      sample                          \n",
       "False sample4                   7149  \n",
       "True  sample4                    216  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Fix\n",
    "df1 = pd.DataFrame(adata.obs[[\"total_counts_outlier\", \"n_genes_by_counts_outlier\" ,\"pct_counts_mt_outlier\", \"sample\"]].value_counts(subset=[\"total_counts_outlier\",  \"sample\"]))\n",
    "df2 = pd.DataFrame(adata.obs[[\"n_genes_by_counts_outlier\" , \"sample\"]].value_counts())\n",
    "df3 = pd.DataFrame(adata.obs[[\"total_counts_outlier\", \"n_genes_by_counts_outlier\" ,\"pct_counts_mt_outlier\", \"sample\"]].value_counts(subset=[\"pct_counts_mt_outlier\",  \"sample\"]))\n",
    "\n",
    "df = pd.concat([df1,df2,df3], axis=1)\n",
    "df.columns = [\"total_counts_outlier\", \"n_genes_by_counts_outlier\", \"pct_counts_mt_outlier\"]\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell filtering based on outlier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving The object at the last step before subsseting\n",
    "if path.exists(DIR_SAVE):\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"raw_adata.h5ad\"))\n",
    "else:\n",
    "    mkdir(DIR_SAVE)\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"raw_adata.h5ad\"))\n",
    "\n",
    "# Cell Filtering based on threshold\n",
    "adata = adata[(~adata.obs.outlier)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = adata.obs.groupby(\"sample\")[keys].agg([\"mean\", \"median\"]).round(3)\n",
    "df2 = adata.obs.groupby(\"sample\")[[\"sample\"]].agg([\"size\"])\n",
    "pd.concat([df1, df2], axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots of confounders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame\n",
    "df = adata.obs[keys+[\"sample\"]]\n",
    "\n",
    "# Determine the number of rows and columns for your subplot grid\n",
    "n = len(df.columns)\n",
    "ncols = 2\n",
    "nrows = 2\n",
    "figsize= 4\n",
    "\n",
    "# Create the subplots\n",
    "wspace = 0.5\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=nrows,\n",
    "    ncols=ncols,\n",
    "    figsize=(ncols * figsize + figsize * wspace * (ncols - 1), nrows * figsize + wspace * (nrows - 1) ),\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(wspace=wspace, hspace=wspace)\n",
    "\n",
    "# Flatten the axes\n",
    "axs = axs.flatten()\n",
    "\n",
    "sns.scatterplot(df, x=\"total_counts\", y=\"n_genes_by_counts\", hue = \"sample\", alpha = 0.4, s = 6,  ax= axs[0])\n",
    "sns.scatterplot(df, x=\"total_counts\", y=\"pct_counts_mt\", hue = \"sample\", alpha = 0.4, s = 6,  ax= axs[1])\n",
    "sns.scatterplot(df, x=\"total_counts\", y=\"pct_counts_rb\", hue = \"sample\", alpha = 0.4, s = 6,  ax= axs[2])\n",
    "\n",
    "if FILTER_DOUBLETS:\n",
    "    sns.scatterplot(df, x=\"total_counts\", y=\"doublet_score\", hue = \"sample\", alpha = 0.4, s = 6,  ax= axs[3])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecontX contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if CORRECT_AMBIENT_RNA and TECHNOLOGY == \"10x\":\n",
    "    ax1 = pw.Brick(figsize=(6,6))\n",
    "    ax2 = pw.Brick(figsize=(6,6))\n",
    "\n",
    "    scatter = sns.scatterplot(pd.concat([adata.obsm[\"decontX_UMAP\"], adata.obs], axis = 1), x = \"DecontX_UMAP_1\", y = \"DecontX_UMAP_2\", hue= \"decontX_contamination\" , s= 0.8, ax = ax1, palette=\"inferno\")\n",
    "    sns.move_legend(scatter, \"center right\", bbox_to_anchor=(1.1, 0.5), title=None, frameon=False)\n",
    "\n",
    "    scatter = sns.scatterplot(pd.concat([adata.obsm[\"decontX_UMAP\"], adata.obs], axis = 1), x = \"DecontX_UMAP_1\", y = \"DecontX_UMAP_2\", hue= \"decontX_clusters\" , s= 0.8, ax=ax2)\n",
    "    sns.move_legend(scatter, \"center right\", bbox_to_anchor=(1.15, 0.5), title=None, frameon=False)\n",
    "\n",
    "    ax12 = ax1+ax2\n",
    "    display(ax12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering after to cell filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata, n_comps=20)\n",
    "sc.pp.neighbors(adata)\n",
    "sc.tl.leiden(adata, key_added=\"groups\", flavor=\"igraph\")\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -.-|m { input: false, output: true, input_fold: show}\n",
    "keys = [\"sample\", \"total_counts\", \"n_genes_by_counts\", \"pct_counts_mt\"]\n",
    "\n",
    "if FILTER_DOUBLETS:\n",
    "    keys = keys + [\"predicted_doublet\"]\n",
    "\n",
    "if CELL_CYCLE_SCORE:\n",
    "    keys = keys + [\"phase\"]\n",
    "\n",
    "figs = sc.pl.umap(adata, size= 7, color= keys, show=False, ncols = 2, color_map=\"inferno\", sort_order=False, alpha = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - [ ] Add error handling if the vars to regress is empty or contain non-keys\n",
    "if REGRESS:\n",
    "    sc.pp.regress_out(adata, keys= VARS_TO_REGRESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambient RNA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CORRECT_AMBIENT_RNA:\n",
    "    sns.violinplot(adata.obs, x = \"decontX_clusters\", y = \"decontX_contamination\")\n",
    "    sns.stripplot(adata.obs, x = \"decontX_clusters\", y = \"decontX_contamination\", s = 1, c = \"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Result\n",
    "if path.exists(DIR_SAVE):\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))\n",
    "else:\n",
    "    mkdir(DIR_SAVE)\n",
    "    adata.write_h5ad(path.join(DIR_SAVE, \"adata.h5ad\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pixi - Python 3 (ipykernel)",
   "language": "python",
   "name": "pixi-kernel-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
